---
layout: single  
title: "ğŸš€æœ¬åœ°éƒ¨ç½²OmniParser v2.0ä¸pyautoguiçœŸæ­£å®ç°è‡ªåŠ¨åŒ–ç‚¹å‡»ï¼æ”¯æŒmacOSã€Windowsä¸Linuxï¼è½»æ¾å®ç°è‡ªåŠ¨åŒ–æ“ä½œç”µè„‘ï¼ä»æœåŠ¡ç«¯éƒ¨ç½²åˆ°å®¢æˆ·ç«¯å¼€å‘ï¼Œä»æ¥å£è®¾è®¡åˆ°è‡ªåŠ¨åŒ–æ§åˆ¶å…¨æµç¨‹"  
sidebar:
  nav: "docs"
date: 2025-02-18 10:00:00 +0800  
categories: LLMs
tags: [OmniParser, OmniParser v2.0, pyautogui, multimoda]
classes: wide  

author_profile: true  
---

OmniParser V2.0æ˜¯å¾®è½¯å¼€å‘çš„ä¸€æ¬¾å…ˆè¿›å¼€æºAIå·¥å…·ï¼Œæ—¨åœ¨å°†å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰æˆªå›¾è½¬æ¢ä¸ºç»“æ„åŒ–æ•°æ®ã€‚è¿™ä¸€åŠŸèƒ½å¢å¼ºäº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸å±å¹•ä¸Šè§†è§‰å…ƒç´ çš„äº’åŠ¨ï¼Œèƒ½å¤Ÿå®ç°æ›´åŠ æ™ºèƒ½çš„è‡ªåŠ¨åŒ–å’Œç”¨æˆ·è¾…åŠ©ã€‚

OmniParser V2.0ä»£è¡¨äº†AIè§†è§‰è§£ææŠ€æœ¯çš„é‡å¤§è¿›æ­¥ï¼Œå®ƒä¸ä»…ä¿ƒè¿›äº†ç”¨æˆ·ä¸æ•°å­—ç•Œé¢ä¹‹é—´çš„æ›´å¥½äº’åŠ¨ï¼Œè¿˜åœ¨å„ç±»åº”ç”¨ä¸­å¢å¼ºäº†è‡ªåŠ¨åŒ–èƒ½åŠ›ã€‚

### **æœ¬ç¯‡ç¬”è®°æ‰€å¯¹åº”çš„è§†é¢‘ï¼š**

- [ğŸ‘‰ğŸ‘‰ğŸ‘‰ é€šè¿‡å“”å“©å“”å“©è§‚çœ‹](https://b23.tv/zB3kDkb)
- [ğŸ‘‰ğŸ‘‰ğŸ‘‰ é€šè¿‡YouTubeè§‚çœ‹](https://youtu.be/aBcedtGCA9I)
- [ğŸ‘‰ğŸ‘‰ğŸ‘‰ æˆ‘çš„å¼€æºé¡¹ç›®](https://github.com/win4r/AISuperDomain)
- [ğŸ‘‰ğŸ‘‰ğŸ‘‰ è¯·æˆ‘å–å’–å•¡](https://ko-fi.com/aila)
- ğŸ‘‰ğŸ‘‰ğŸ‘‰ æˆ‘çš„å¾®ä¿¡ï¼šstoeng ã€åŠ æˆ‘è¯·æ³¨æ˜æ¥æ„ã€‘
- ğŸ‘‰ğŸ‘‰ğŸ‘‰ æ‰¿æ¥å¤§æ¨¡å‹å¾®è°ƒã€RAGã€AIæ™ºèƒ½ä½“ã€AIç›¸å…³åº”ç”¨å¼€å‘ç­‰é¡¹ç›®ã€‚

### ä¸»è¦ç‰¹ç‚¹

- **é€Ÿåº¦ä¸æ•ˆç‡**ï¼šä¸å…¶å‰ç‰ˆæœ¬ç›¸æ¯”ï¼ŒOmniParser V2.0æ˜¾è‘—å‡å°‘äº†çº¦60%çš„å¤„ç†å»¶è¿Ÿï¼Œåœ¨é«˜ç«¯GPUï¼ˆå¦‚A100ï¼‰ä¸Šçš„å¹³å‡å¤„ç†æ—¶é—´ä¸º0.6ç§’ï¼Œåœ¨4090å‹å·ä¸Šä¸º0.8ç§’ã€‚
- **å¢å¼ºçš„å‡†ç¡®æ€§**ï¼šè¯¥å·¥å…·åœ¨æ£€æµ‹äº¤äº’å…ƒç´ æ–¹é¢çš„å¹³å‡å‡†ç¡®ç‡ä¸º39.6%ï¼Œç›¸æ¯”æ—©æœŸç‰ˆæœ¬æœ‰äº†æ˜¾è‘—æå‡ã€‚è¿™ä¸€å‡†ç¡®ç‡é€šè¿‡ä½¿ç”¨ç²¾ç»†è°ƒä¼˜çš„YOLOv8æ¨¡å‹å’Œæ‰©å±•çš„è®­ç»ƒæ•°æ®é›†ï¼ˆæ¶µç›–å„ç§UIç»„ä»¶ï¼‰å¾—ä»¥å®ç°ã€‚
- **å¼ºå¤§çš„è¾“å…¥/è¾“å‡ºèƒ½åŠ›**ï¼šOmniParseræ”¯æŒæ¥è‡ªå¤šä¸ªå¹³å°çš„æˆªå›¾ï¼ŒåŒ…æ‹¬Windowså’Œç§»åŠ¨è®¾å¤‡ã€‚å®ƒèƒ½å¤Ÿç”ŸæˆUIå…ƒç´ çš„ç»“æ„åŒ–è¡¨ç¤ºï¼Œè¯¦ç»†æè¿°å¯ç‚¹å‡»åŒºåŸŸåŠå…¶åŠŸèƒ½ã€‚
- **ä¸LLMçš„æ— ç¼é›†æˆ**ï¼šè¯¥å·¥å…·é€šè¿‡ç»Ÿä¸€æ¥å£OmniToolä¸å¤šä¸ªAIæ¨¡å‹é›†æˆï¼Œå¦‚OpenAIçš„GPT-4oã€DeepSeek R1ã€Qwen 2.5VLå’ŒAnthropic Sonnetã€‚è¿™ç§é›†æˆä½¿å¾—åˆ›å»ºè‡ªåŠ¨åŒ–æµ‹è¯•å·¥å…·å’Œè¾…åŠ©æŠ€æœ¯è§£å†³æ–¹æ¡ˆæˆä¸ºå¯èƒ½ã€‚

### åº”ç”¨é¢†åŸŸ

OmniParser V2.0æœ‰å¹¿æ³›çš„åº”ç”¨åœºæ™¯ï¼š

- **UIè‡ªåŠ¨åŒ–**ï¼šé€šè¿‡è®©AIä»£ç†ä¸GUIäº’åŠ¨æ¥è‡ªåŠ¨åŒ–é‡å¤ä»»åŠ¡ã€‚
- **è¾…åŠ©æŠ€æœ¯è§£å†³æ–¹æ¡ˆ**ï¼šä¸ºæ®‹éšœç”¨æˆ·æä¾›ç»“æ„åŒ–æ•°æ®ï¼Œå¸®åŠ©è¾…åŠ©æŠ€æœ¯çš„å®ç°ã€‚
- **ç”¨æˆ·ç•Œé¢åˆ†æ**ï¼šæ ¹æ®ä»æˆªå›¾ä¸­æå–çš„æ•°æ®åˆ†æUIè®¾è®¡ï¼Œæå‡å¯ç”¨æ€§[2][4]ã€‚

### ğŸš€å®‰è£…æ­¥éª¤

```bash
conda create -n "omni" python==3.12 -y && conda activate omni

git clone https://github.com/microsoft/OmniParser.git

cd OmniParser

pip install -r requirements.txt

# ä¸‹è½½V2æ¨¡å‹æƒé‡
rm -rf weights/icon_detect weights/icon_caption weights/icon_caption_florence 
for f in icon_detect/{train_args.yaml,model.pt,model.yaml} icon_caption/{config.json,generation_config.json,model.safetensors}; do
    huggingface-cli download microsoft/OmniParser-v2.0 "$f" --local-dir weights
done
mv weights/icon_caption weights/icon_caption_florence

# å¯åŠ¨UI
python gradio_demo.py

# æœåŠ¡ç«¯é…ç½®

cd ~/OmniParser

pip install fastapi uvicorn python-multipart pillow requests

nano main.py

python main.py
```

### ğŸš€pyautogui

```bash
# pip install pyautogui

from time import sleep

import pyautogui
import time

def bbox_to_coords(bbox, screen_width, screen_height):
    """å°† bbox åæ ‡è½¬æ¢ä¸ºå±å¹•åæ ‡."""
    xmin, ymin, xmax, ymax = bbox
    x_center = int((xmin + xmax) / 2 * screen_width)
    y_center = int((ymin + ymax) / 2 * screen_height)
    return x_center, y_center

def click_bbox(bbox):
    """ç‚¹å‡»æŒ‡å®šçš„ bbox."""
    screen_width, screen_height = pyautogui.size()
    x, y = bbox_to_coords(bbox, screen_width, screen_height)

    # ç§»åŠ¨é¼ æ ‡åˆ°æŒ‡å®šä½ç½®
    pyautogui.moveTo(x, y, duration=0.2)  # duration æ˜¯ç§»åŠ¨æ—¶é—´ï¼Œå•ä½ä¸ºç§’

    # ç‚¹å‡»é¼ æ ‡
    pyautogui.click()

    print(f"ç‚¹å‡»äº†åæ ‡: x={x}, y={y}")

if __name__ == '__main__':

    sleep(5)

    # ç¤ºä¾‹ bbox (æ¥è‡ªæ‚¨æä¾›çš„æ•°æ®)
    bbox = [0.36728453636169434, 0.9408491849899292, 0.39909330010414124, 0.9875121712684631] # chrome

    # ç‚¹å‡» bbox
    click_bbox(bbox)
```

### ğŸš€server

```python
# pip install fastapi uvicorn python-multipart pillow requests

from fastapi import FastAPI, UploadFile, File
from fastapi.responses import JSONResponse
import torch
from PIL import Image
import io
import base64
from typing import Optional
import numpy as np

from util.utils import check_ocr_box, get_yolo_model, get_caption_model_processor, get_som_labeled_img

app = FastAPI()

# åˆå§‹åŒ–æ¨¡å‹
yolo_model = get_yolo_model(model_path='weights/icon_detect/model.pt')
caption_model_processor = get_caption_model_processor(
    model_name="florence2", 
    model_name_or_path="weights/icon_caption_florence"
)

DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

@app.post("/process_image")
async def process_image(
    file: UploadFile = File(...),
    box_threshold: float = 0.05,
    iou_threshold: float = 0.1,
    use_paddleocr: bool = True,
    imgsz: int = 640
):
    try:
        # è¯»å–ä¸Šä¼ çš„å›¾ç‰‡
        contents = await file.read()
        image = Image.open(io.BytesIO(contents))
        
        # ä¸´æ—¶ä¿å­˜å›¾ç‰‡
        image_save_path = 'imgs/temp_image.png'
        image.save(image_save_path)
        
        # é…ç½®ç»˜åˆ¶è¾¹ç•Œæ¡†çš„å‚æ•°
        box_overlay_ratio = image.size[0] / 3200
        draw_bbox_config = {
            'text_scale': 0.8 * box_overlay_ratio,
            'text_thickness': max(int(2 * box_overlay_ratio), 1),
            'text_padding': max(int(3 * box_overlay_ratio), 1),
            'thickness': max(int(3 * box_overlay_ratio), 1),
        }

        # OCRå¤„ç†
        ocr_bbox_rslt, is_goal_filtered = check_ocr_box(
            image_save_path,
            display_img=False,
            output_bb_format='xyxy',
            goal_filtering=None,
            easyocr_args={'paragraph': False, 'text_threshold': 0.9},
            use_paddleocr=use_paddleocr
        )
        text, ocr_bbox = ocr_bbox_rslt

        # è·å–æ ‡è®°åçš„å›¾ç‰‡å’Œè§£æå†…å®¹
        dino_labled_img, label_coordinates, parsed_content_list = get_som_labeled_img(
            image_save_path,
            yolo_model,
            BOX_TRESHOLD=box_threshold,
            output_coord_in_ratio=True,
            ocr_bbox=ocr_bbox,
            draw_bbox_config=draw_bbox_config,
            caption_model_processor=caption_model_processor,
            ocr_text=text,
            iou_threshold=iou_threshold,
            imgsz=imgsz,
        )

        # æ ¼å¼åŒ–è§£æç»“æœ
        parsed_content = '\n'.join([f'icon {i}: {str(v)}' for i, v in enumerate(parsed_content_list)])

        return JSONResponse({
            "status": "success",
            "labeled_image": dino_labled_img,  # base64ç¼–ç çš„å›¾ç‰‡
            "parsed_content": parsed_content,
            "label_coordinates": label_coordinates
        })

    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"status": "error", "message": str(e)}
        )

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

### ğŸš€Client

```python
import requests
from PIL import Image
import base64
import io
import pyautogui
from time import sleep
import json
import ast  # ç”¨äºè§£æå­—ç¬¦ä¸²å½¢å¼çš„å­—å…¸

def process_image(
        image_path: str,
        api_url: str = "http://192.168.1.105:8000/process_image",
        box_threshold: float = 0.05,
        iou_threshold: float = 0.1,
        use_paddleocr: bool = True,
        imgsz: int = 640
):
    files = {
        'file': ('image.png', open(image_path, 'rb'), 'image/png')
    }

    params = {
        'box_threshold': box_threshold,
        'iou_threshold': iou_threshold,
        'use_paddleocr': use_paddleocr,
        'imgsz': imgsz
    }

    response = requests.post(api_url, files=files, params=params)

    if response.status_code == 200:
        result = response.json()

        if result['status'] == 'success':
            labeled_image = Image.open(io.BytesIO(base64.b64decode(result['labeled_image'])))
            return {
                'status': 'success',
                'labeled_image': labeled_image,
                'parsed_content': result['parsed_content'],
                'label_coordinates': result['label_coordinates']
            }
        else:
            return {'status': 'error', 'message': result.get('message', 'Unknown error')}
    else:
        return {'status': 'error', 'message': f'HTTP error {response.status_code}'}

def parse_icon_data(content_str):
    """è§£æåŒ…å«å›¾æ ‡æ•°æ®çš„å­—ç¬¦ä¸²ä¸ºåˆ—è¡¨."""
    icons = []
    lines = content_str.strip().split('\n')
    for line in lines:
        if line.startswith('icon '):
            try:
                # æå–èŠ±æ‹¬å·ä¸­çš„å†…å®¹
                dict_str = line[line.index('{'):line.rindex('}') + 1]
                # è§£æå­—ç¬¦ä¸²ä¸ºå­—å…¸
                icon_data = ast.literal_eval(dict_str)
                icons.append(icon_data)
            except Exception as e:
                print(f"è§£æé”™è¯¯: {e}")
                continue
    return icons

def bbox_to_coords(bbox, screen_width, screen_height):
    """å°† bbox åæ ‡è½¬æ¢ä¸ºå±å¹•åæ ‡."""
    xmin, ymin, xmax, ymax = bbox

    # è€ƒè™‘ Mac é¡¶éƒ¨èœå•æ çš„åç§»
    menu_bar_height = 25

    # å‘ä¸Šåç§»ä»¥é¿å…ç‚¹å‡»åˆ°æ–‡ä»¶å
    y_offset = -15  # å‘ä¸Šåç§»15åƒç´ 

    # è®¡ç®—ç›¸å¯¹åæ ‡
    x_center = int((xmin + xmax) / 2 * screen_width)
    y_center = int((ymin + ymax) / 2 * (screen_height - menu_bar_height)) + menu_bar_height + y_offset

    # æ·»åŠ è°ƒè¯•ä¿¡æ¯
    print(f"\nåæ ‡è½¬æ¢è¯¦æƒ…:")
    print(f"å±å¹•å°ºå¯¸: {screen_width} x {screen_height}")
    print(f"åŸå§‹bbox: {bbox}")
    print(f"xè½´å˜æ¢: {xmin:.4f} -> {xmax:.4f} ä¸­ç‚¹: {(xmin + xmax) / 2:.4f}")
    print(f"yè½´å˜æ¢: {ymin:.4f} -> {ymax:.4f} ä¸­ç‚¹: {(ymin + ymax) / 2:.4f}")
    print(f"è€ƒè™‘èœå•æ åç§»: {menu_bar_height}px")
    print(f"å‘ä¸Šåç§»: {y_offset}px")
    print(f"è®¡ç®—ç»“æœ: x={x_center}, y={y_center}")

    # ç¡®ä¿åæ ‡åœ¨å±å¹•èŒƒå›´å†…
    x_center = max(0, min(x_center, screen_width))
    y_center = max(0, min(y_center, screen_height))

    return x_center, y_center

# def bbox_to_coords(bbox, screen_width, screen_height):
#     """å°† bbox åæ ‡è½¬æ¢ä¸ºå±å¹•åæ ‡."""
#     xmin, ymin, xmax, ymax = bbox
#
#     # è€ƒè™‘ Mac é¡¶éƒ¨èœå•æ çš„åç§»ï¼ˆå¤§çº¦25åƒç´ ï¼‰
#     menu_bar_height = 25
#
#     # è€ƒè™‘çª—å£è¾¹æ¡†å’Œå…¶ä»–å¯èƒ½çš„åç§»
#     x_offset = 0
#     y_offset = menu_bar_height
#
#     # è®¡ç®—ç›¸å¯¹åæ ‡
#     x_center = int((xmin + xmax) / 2 * screen_width)
#     y_center = int((ymin + ymax) / 2 * (screen_height - menu_bar_height)) + y_offset
#
#     # æ·»åŠ è°ƒè¯•ä¿¡æ¯
#     print(f"\nåæ ‡è½¬æ¢è¯¦æƒ…:")
#     print(f"å±å¹•å°ºå¯¸: {screen_width} x {screen_height}")
#     print(f"åŸå§‹bbox: {bbox}")
#     print(f"xè½´å˜æ¢: {xmin:.4f} -> {xmax:.4f} ä¸­ç‚¹: {(xmin + xmax) / 2:.4f}")
#     print(f"yè½´å˜æ¢: {ymin:.4f} -> {ymax:.4f} ä¸­ç‚¹: {(ymin + ymax) / 2:.4f}")
#     print(f"è€ƒè™‘èœå•æ åç§»: {menu_bar_height}px")
#     print(f"è®¡ç®—ç»“æœ: x={x_center}, y={y_center}")
#
#     # ç¡®ä¿åæ ‡åœ¨å±å¹•èŒƒå›´å†…
#     x_center = max(0, min(x_center, screen_width))
#     y_center = max(0, min(y_center, screen_height))
#
#     return x_center, y_center

def click_bbox(bbox):
    """åŒå‡»æŒ‡å®šçš„ bbox."""
    # è·å–å±å¹•åˆ†è¾¨ç‡
    screen_width, screen_height = pyautogui.size()
    print(f"å½“å‰å±å¹•åˆ†è¾¨ç‡: {screen_width}x{screen_height}")

    # è·å–ç‚¹å‡»åæ ‡
    x, y = bbox_to_coords(bbox, screen_width, screen_height)

    print(f"\nå³å°†æ‰§è¡ŒåŒå‡»:")
    print(f"ç›®æ ‡åæ ‡: x={x}, y={y}")
    print("3ç§’å‡†å¤‡æ—¶é—´...")
    sleep(3)

    # ç§»åŠ¨é¼ æ ‡åˆ°æŒ‡å®šä½ç½®
    pyautogui.moveTo(x, y, duration=0.5)

    print("é¼ æ ‡å·²å°±ä½ï¼Œ1ç§’ååŒå‡»...")
    sleep(1)

    # æ‰§è¡ŒåŒå‡»
    pyautogui.doubleClick()

    print(f"å·²åŒå‡»åæ ‡: x={x}, y={y}")

# def click_bbox(bbox):
#     """ç‚¹å‡»æŒ‡å®šçš„ bbox."""
#     # è·å–å±å¹•åˆ†è¾¨ç‡
#     screen_width, screen_height = pyautogui.size()
#     print(f"å½“å‰å±å¹•åˆ†è¾¨ç‡: {screen_width}x{screen_height}")
#
#     # è·å–ç‚¹å‡»åæ ‡
#     x, y = bbox_to_coords(bbox, screen_width, screen_height)
#
#     print(f"\nå³å°†æ‰§è¡Œç‚¹å‡»:")
#     print(f"ç›®æ ‡åæ ‡: x={x}, y={y}")
#     print("3ç§’å‡†å¤‡æ—¶é—´...")
#     sleep(3)
#
#     # ç§»åŠ¨é¼ æ ‡åˆ°æŒ‡å®šä½ç½®ï¼ˆä½¿ç”¨ç¼“åŠ¨æ•ˆæœï¼‰
#     pyautogui.moveTo(x, y, duration=1, tween=pyautogui.easeOutQuad)
#
#     print("é¼ æ ‡å·²å°±ä½ï¼Œ1ç§’åç‚¹å‡»...")
#     sleep(1)
#
#     # è·å–å½“å‰é¼ æ ‡ä½ç½®ä»¥éªŒè¯
#     current_x, current_y = pyautogui.position()
#     print(f"å½“å‰é¼ æ ‡ä½ç½®: x={current_x}, y={current_y}")
#
#     # ç‚¹å‡»é¼ æ ‡
#     pyautogui.click()
#     print(f"å·²ç‚¹å‡»åæ ‡: x={x}, y={y}")

def find_dog_avif_coordinates(icons):
    """åœ¨è§£æå†…å®¹ä¸­æŸ¥æ‰¾ dog.avif çš„å›¾æ ‡."""
    for i, icon in enumerate(icons):
        if isinstance(icon, dict) and 'content' in icon:
            content = icon['content'].strip().lower()
            if 'dog.avif' in content:
                print(f"æ‰¾åˆ° dog.avifï¼Œå›¾æ ‡ç´¢å¼•: {i}")
                return icon['bbox']
    return None

if __name__ == "__main__":
    # è·å–å¹¶æ‰“å°å±å¹•åˆ†è¾¨ç‡
    screen_width, screen_height = pyautogui.size()
    print(f"å½“å‰å±å¹•åˆ†è¾¨ç‡: {screen_width}x{screen_height}")

    image_path = "s.png"
    result = process_image(
        image_path=image_path,
        box_threshold=0.05,
        iou_threshold=0.1,
        use_paddleocr=True,
        imgsz=640
    )

    if result['status'] == 'success':
        icons = parse_icon_data(result['parsed_content'])
        dog_avif_bbox = find_dog_avif_coordinates(icons)

        if dog_avif_bbox:
            print("æ‰¾åˆ° dog.avif åæ ‡:", dog_avif_bbox)
            click_bbox(dog_avif_bbox)
        else:
            print("æœªæ‰¾åˆ° dog.avif å›¾æ ‡")
    else:
        print("Error:", result['message'])

# print(f"å½“å‰å±å¹•åˆ†è¾¨ç‡: {pyautogui.size()}")

```

