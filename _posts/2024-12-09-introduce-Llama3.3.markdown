---
layout: single  
title: "Llama-3.3â€“70Béœ‡æ’¼ç™»åœºï¼70bå‚æ•°128kä¸Šä¸‹æ–‡æ€§èƒ½æ¥è¿‘gpt4ï¼æœ€å¼ºå¼€æºå¤§æ¨¡å‹ï¼Œæ”¯æŒç®€ä½“ä¸­æ–‡å’Œç¹ä½“ä¸­æ–‡ï¼Cline+Aiderå®ç°å…¨è‡ªåŠ¨ç¼–ç¨‹ï¼AutoGenå®ç°æœ€å¼ºAIæ™ºèƒ½ä½“ï¼"  
sidebar:
  nav: "docs"
date: 2024-12-09 10:00:00 +0800  
categories: LLMs
tags: [Llama 3.3, Meta, Open Source, Language Model]
classes: wide  

author_profile: true  
---


Metaäº2024å¹´12æœˆ6æ—¥æ­£å¼å‘å¸ƒäº†æ–°ä¸€ä»£å¼€æºå¤§å‹è¯­è¨€æ¨¡å‹Llama 3.3ã€‚è¯¥æ¨¡å‹åœ¨ä»…æœ‰700äº¿å‚æ•°çš„æƒ…å†µä¸‹ï¼Œå®ç°äº†ä¸æ­¤å‰4050äº¿å‚æ•°æ¨¡å‹ç›¸å½“çš„æ€§èƒ½ï¼Œæ ‡å¿—ç€è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸçš„é‡å¤§çªç ´ã€‚ 

### æœ¬ç¯‡ç¬”è®°æ‰€å¯¹åº”çš„è§†é¢‘ï¼š

- [ğŸ‘‰ğŸ‘‰ğŸ‘‰ é€šè¿‡å“”å“©å“”å“©è§‚çœ‹](https://b23.tv/uFAO2FG)
- [ğŸ‘‰ğŸ‘‰ğŸ‘‰ é€šè¿‡YouTubeè§‚çœ‹](https://youtu.be/MRRFyl5d958)

## æŠ€æœ¯åˆ›æ–°ä¸æ¶æ„ä¼˜åŒ–

Llama 3.3é‡‡ç”¨äº†ä¼˜åŒ–çš„Transformeræ¶æ„ï¼Œç»“åˆäº†ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’ŒåŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰æŠ€æœ¯ï¼Œä½¿æ¨¡å‹æ›´ç¬¦åˆäººç±»åå¥½ã€‚æ­¤å¤–ï¼Œæ¨¡å‹å¼•å…¥äº†åˆ†ç»„æŸ¥è¯¢æ³¨æ„åŠ›ï¼ˆGQAï¼‰æœºåˆ¶ï¼Œæå‡äº†æ¨ç†é˜¶æ®µçš„æ€§èƒ½å’Œå¯æ‰©å±•æ€§ã€‚å€¼å¾—ä¸€æçš„æ˜¯ï¼ŒLlama 3.3æ”¯æŒé•¿è¾¾128Kçš„ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œçº¦ç­‰äº400é¡µæ–‡æœ¬ï¼Œåœ¨å¤„ç†é•¿æ–‡æœ¬æ—¶è¡¨ç°å‡ºè‰²ã€‚

## å¤šè¯­è¨€æ”¯æŒä¸åº”ç”¨åœºæ™¯

Llama 3.3å…·å¤‡å¼ºå¤§çš„å¤šè¯­è¨€å¤„ç†èƒ½åŠ›ï¼Œæ”¯æŒåŒ…æ‹¬è‹±è¯­ã€å¾·è¯­ã€æ³•è¯­ã€æ„å¤§åˆ©è¯­ã€è‘¡è„ç‰™è¯­ã€å°åœ°è¯­ã€è¥¿ç­ç‰™è¯­å’Œæ³°è¯­åœ¨å†…çš„å…«ç§è¯­è¨€ã€‚è¿™ä½¿å…¶åœ¨å…¨çƒèŒƒå›´å†…çš„åº”ç”¨æ›´å…·å¹¿æ³›æ€§ã€‚åŒæ—¶ï¼Œæ¨¡å‹èƒ½å¤Ÿç”Ÿæˆç»“æ„åŒ–çš„æ¨ç†è¿‡ç¨‹å’Œç²¾ç¡®çš„JSONæ ¼å¼å“åº”ï¼Œé€‚ç”¨äºå¤šç§è‡ªç„¶è¯­è¨€ç”Ÿæˆä»»åŠ¡ã€‚ 

## éƒ¨ç½²æˆæœ¬ä¸ç¤¾åŒºåé¦ˆ

ä¸ä¹‹å‰çš„æ¨¡å‹ç›¸æ¯”ï¼ŒLlama 3.3æ˜¾è‘—é™ä½äº†éƒ¨ç½²æˆæœ¬ã€‚åœ¨Metaåˆä½œçš„å¹³å°ä¸­ï¼ŒLlama 3.3çš„ä½¿ç”¨è´¹ç”¨ä»…ä¸ºLlama 3.1 405Bçš„ååˆ†ä¹‹ä¸€è‡³å››åˆ†ä¹‹ä¸€ã€‚ç›®å‰ï¼Œæ¨¡å‹æƒé‡å·²åœ¨å®˜ç½‘å’ŒHugging Faceä¸Šå¼€æ”¾ä¸‹è½½ï¼Œå¼€å‘è€…å¯ä»¥æ ¹æ®Llama 3.3ç¤¾åŒºè®¸å¯åè®®è¿›è¡Œä½¿ç”¨ã€‚ 

## ä½¿ç”¨æŒ‡å—ä¸å®è·µ

å¼€å‘è€…å¯ä»¥é€šè¿‡Ollamaç­‰å·¥å…·è¿è¡ŒLlama 3.3æ¨¡å‹ã€‚ä»¥ä¸‹æ˜¯ä½¿ç”¨Ollamaè¿è¡ŒLlama 3.3çš„ç¤ºä¾‹ä»£ç ï¼š


```bash
ollama run llama3.3
```

### ç®—æ³•æµ‹è¯•é¢˜

- [x] è¬›å€‹æ•…äº‹å§
- [x] how many 'r's in strawberrrry?
- [x] ç”¨ python å®ç°è®¡ç®— 179424673 æ˜¯ç¬¬å‡ ä¸ªè´¨æ•°ï¼Ÿ
- [x] ä¸‰ä½ä¼ æ•™å£«å’Œä¸‰ä½é£Ÿäººæ—éœ€è¦è¿‡æ²³ã€‚
  ä»–ä»¬æœ‰ä¸€è‰˜èˆ¹ï¼Œæ¯æ¬¡æœ€å¤šå¯ä»¥è½½ä¸¤äººã€‚
  å¦‚æœåœ¨ä»»ä½•æ—¶å€™ï¼Œé£Ÿäººæ—çš„æ•°é‡è¶…è¿‡äº†ä¼ æ•™å£«çš„æ•°é‡ï¼ˆæ— è®ºæ˜¯åœ¨æ²³çš„å“ªä¸€ä¾§ï¼‰ï¼Œé£Ÿäººæ—å°±ä¼šåƒæ‰ä¼ æ•™å£«ã€‚
  å¦‚ä½•è®©æ‰€æœ‰å…­ä¸ªäººå®‰å…¨è¿‡æ²³ï¼Ÿè¯·æä¾›åˆ†æ­¥éª¤çš„è§£å†³æ–¹æ¡ˆï¼Œå¹¶ç”¨ ASCII å›¾ç¤ºå±•ç¤ºè§£å†³æ–¹æ¡ˆã€‚


### AutoGenè°ƒç”¨Llama3.3ä»£ç 

```python
You are an expert AI assistant tasked with providing thorough, step-by-step reasoning for complex problems or questions. Follow these guidelines:

1. For each step in your reasoning process:
   - Provide a clear, descriptive title
   - Explain your thought process in detail
   - Use markdown formatting for better readability

2. Use at least 3 different methods or approaches to analyze the problem

3. Include exploration of alternative answers and potential errors in your reasoning

4. Be aware of your limitations as a language model and explicitly state what you can and cannot do

5. When re-examining your reasoning, use a genuinely different approach

6. Apply best practices in problem-solving and critical thinking

7. Conclude with a final answer only when you've exhausted your analysis

8. Structure your response as follows:

```` ``json
{
  "step": 1,
  "title": "Identifying Key Information",
  "content": "## Identifying Key Information\n\nTo begin solving this problem, we need to carefully examine the given information and identify the crucial elements that will guide our solution process. This involves...",
  "next_action": "continue"
}
```` ``

9. For the final step, use "next_action": "final_answer" and include your conclusion

10. Strive for clarity, thoroughness, and intellectual honesty in your analysis

How many 'r's in strawberrrry?
aider
python -m pip install -U aider-chat


export OPENROUTER_API_KEY=<key> # Mac/Linux
setx   OPENROUTER_API_KEY <key> # Windows, restart shell after setx

aider --model openrouter/meta-llama/llama-3.3-70b-instruct


autogen
#è¿™æ˜¯ä¸€ä¸ªå¤šä»£ç†ï¼ˆmulti-agentï¼‰åä½œèŠå¤©ç³»ç»Ÿç¤ºä¾‹ï¼Œå®ƒé€šè¿‡å¤šä¸ªè§’è‰²ï¼ˆåˆ†æä¸“å®¶ã€è§£å†³æ–¹æ¡ˆä¸“å®¶å’Œæ•´åˆä¸“å®¶ï¼‰å¯¹è¾“å…¥é—®é¢˜è¿›è¡Œå¤„ç†å’Œå›ç­”ã€‚
#ä»£ç çš„æ ¸å¿ƒé€»è¾‘æ˜¯ä½¿ç”¨GroupChatå’ŒGroupChatManagerå°†å¤šä¸ªåŠ©æ‰‹æœºå™¨äººï¼ˆAssistantAgentï¼‰åè°ƒèµ·æ¥ï¼Œä»¥åˆ†æ­¥éª¤è§£å†³é—®é¢˜å¹¶æœ€ç»ˆç”Ÿæˆä¸€ä¸ªæ•´åˆåçš„æŠ¥å‘Šã€‚


# å¯¼å…¥å¿…è¦çš„åº“
import os
from autogen import AssistantAgent, UserProxyAgent, GroupChat, GroupChatManager, config_list_from_json
import openai
from google.colab import userdata


# è®¾ç½®LLM APIå¯†é’¥
#
# os.environ["OPENAI_API_KEY"] = userdata.get('OPENAI_API_KEY')
# openai.api_key = os.getenv("OPENAI_API_KEY")

# LLMæ¨¡å‹é…ç½®
# model: ä½¿ç”¨çš„GPTæ¨¡å‹
# temperature: æ§åˆ¶è¾“å‡ºçš„éšæœºæ€§ï¼Œè¶Šé«˜è¶Šéšæœºï¼Œè¶Šä½è¶Šç¡®å®š
# llm_config = {
#     "model": "gpt-4o-mini",
#     "api_key": os.getenv("OPENAI_API_KEY"),
#     "temperature": 0.7,
# }

os.environ["OPENROUTER_API_KEY"] = userdata.get('OPENROUTER_API_KEY')



llm_config = {
    "config_list": [
        {
            "model": "meta-llama/llama-3.3-70b-instruct",
            "base_url":"https://openrouter.ai/api/v1",
            "api_key":os.getenv("OPENROUTER_API_KEY"),
        }
    ]
}


def process_question(question):
    """
    ä½¿ç”¨GroupChatå¤„ç†é—®é¢˜çš„ä¸»è¦å‡½æ•°
    å‚æ•°:
        question: éœ€è¦åˆ†æå’Œè§£å†³çš„é—®é¢˜
    è¿”å›:
        å¤„ç†åçš„æœ€ç»ˆå›ç­”æˆ–é”™è¯¯ä¿¡æ¯
    """

    try:
        # åˆ›å»ºç”¨æˆ·ä»£ç†
        # ä½œä¸ºç”¨æˆ·ä¸å…¶ä»–AIä»£ç†äº¤äº’çš„æ¡¥æ¢
        # human_input_mode="NEVER"è¡¨ç¤ºä¸éœ€è¦äººç±»å¹²é¢„
        user_proxy = UserProxyAgent(
            name="user_proxy",
            system_message="A proxy for the user to communicate with the group chat.",
            human_input_mode="NEVER"
        )

        # åˆ›å»ºåˆ†æä¸“å®¶ä»£ç†
        # è´Ÿè´£é—®é¢˜åˆ†æï¼Œè¯†åˆ«å…³é”®ç»„ä»¶å’ŒæŒ‘æˆ˜
        analyst = AssistantAgent(
            name="analyst",
            system_message="""You are an analysis expert. Your task is ONLY to:
            1. Analyze the given problem thoroughly
            2. Identify key components and challenges
            3. Provide a structured analysis
            4. End your analysis with clear conclusions
            DO NOT propose solutions - that is the Solution Explorer's job.""",
            llm_config=llm_config
        )

        # åˆ›å»ºè§£å†³æ–¹æ¡ˆä¸“å®¶ä»£ç†
        # åŸºäºåˆ†æç»“æœæå‡ºå…·ä½“è§£å†³æ–¹æ¡ˆ
        solution_explorer = AssistantAgent(
            name="solution_explorer",
            system_message="""You are a solution architect. Your task is ONLY to:
            1. Review the analyst's analysis
            2. Propose concrete solutions
            3. Provide implementation steps
            4. End with clear recommendations
            Focus ONLY on solutions, the analysis has already been done.""",
            llm_config=llm_config
        )

        # åˆ›å»ºæŠ€æœ¯æ–‡æ¡£æ’°å†™ä»£ç†
        # è´Ÿè´£æ•´åˆåˆ†æå’Œè§£å†³æ–¹æ¡ˆï¼Œç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        integrator = AssistantAgent(
            name="integrator",
            system_message="""You are a technical writer. Your task is to:
            1. Review both the analysis and solutions provided
            2. Create a comprehensive final report
            3. Ensure all sections are properly integrated
            4. End with actionable conclusions""",
            llm_config=llm_config
        )

        # åˆ›å»ºç¾¤èŠï¼Œå°†æ‰€æœ‰ä»£ç†åŠ å…¥å…¶ä¸­
        # max_round=4ç¡®ä¿æ¯ä¸ªä»£ç†éƒ½æœ‰æœºä¼šå‘è¨€
        groupchat = GroupChat(
            agents=[user_proxy, analyst, solution_explorer, integrator],
            messages=[],
            max_round=4  # å¢åŠ è½®æ•°ä»¥ç¡®ä¿æ¯ä¸ªagentéƒ½æœ‰æœºä¼šå‘è¨€
        )

        # åˆ›å»ºç¾¤èŠç®¡ç†å™¨ï¼Œæ§åˆ¶å¯¹è¯æµç¨‹
        manager = GroupChatManager(groupchat=groupchat, llm_config=llm_config)

        # æ„å»ºåˆå§‹é—®é¢˜æ¶ˆæ¯
        # å®šä¹‰æ˜ç¡®çš„å¤„ç†æµç¨‹å’Œæ¯ä¸ªä»£ç†çš„ä»»åŠ¡
        initial_message = f"""
        Please help analyze and provide solutions for: {question}

        Follow this EXACT process:
        1. First, Analyst will ONLY provide analysis
        2. Then, Solution Explorer will ONLY provide solutions based on the analysis
        3. Finally, Integrator will create the final report

        Each agent must wait for the previous agent to complete their task before starting.
        Analyst: Start by providing ONLY the analysis.
        """

        # å‘èµ·å¯¹è¯
        chat_result = user_proxy.initiate_chat(
            manager,
            message=initial_message
        )

        # ä»å¯¹è¯å†å²ä¸­è·å–æœ€ç»ˆç»“æœ
        # è¿”å›æœ€åä¸€æ¡æœ‰æ•ˆæ¶ˆæ¯
        final_messages = chat_result.chat_history
        if final_messages:
            for msg in reversed(final_messages):
                if msg.get('content'):
                    return msg['content']

        return "No valid response generated"

    except Exception as e:
        return f"Error in processing: {str(e)}"

def main():
    # è®¾ç½®æ—¥å¿—
    import logging
    logging.basicConfig(level=logging.INFO)

    # ç¤ºä¾‹é—®é¢˜
    question = "How to implement a secure authentication system?"
    print("\nProcessing question:", question)
    print("\nGenerating response...\n")

    # å¤„ç†é—®é¢˜å¹¶è¾“å‡ºç»“æœ
    try:
        response = process_question(question)
        print("\nFinal Response:")
        print(response)
    except Exception as e:
        print(f"Error occurred: {str(e)}")

# ç¨‹åºå…¥å£ç‚¹
if __name__ == "__main__":
    main()
```