---
layout: single
title: "ğŸš€é‡ç£…é¦–å‘ï¼æœ¬åœ°éƒ¨ç½²+çœŸå®æµ‹è¯„é˜¿é‡Œå¼€æºè§†è§‰å¤§æ¨¡å‹Qwen2.5-VL-7B-Instructå’ŒQwen2.5-VL-72Bï¼è½»æ¾è¯†åˆ«æå–å‘ç¥¨ï¼å…¨æ–¹ä½æµ‹è¯„è§è¯AIè§†è§‰ç†è§£èƒ½åŠ›çš„è´¨çš„é£è·ƒï¼Œå›¾åƒè¯†åˆ«ä¸å†æ˜¯éš¾é¢˜"
sidebar:
  nav: "docs"
date: 2025-01-30 00:00:00 +0800
categories: LLMs
tags: [Qwen2.5-VL, Qwen2.5-VL-7B-Instruct, Qwen2.5, é˜¿é‡Œå·´å·´, Qwen2.5-VL-7B, Qwen2.5-VL-72B, LLMs]
classes: wide
author_profile: true
---

2025å¹´1æœˆï¼Œé˜¿é‡Œå·´å·´é€šä¹‰åƒé—®å›¢é˜Ÿå‘å¸ƒäº†å…¨æ–°çš„è§†è§‰è¯­è¨€æ¨¡å‹â€”â€”Qwen2.5-VL-7B-Instructï¼Œä½œä¸ºQwen2.5-VLç³»åˆ—çš„ä¸€å‘˜ï¼Œæ ‡å¿—ç€è§†è§‰è¯­è¨€ç†è§£é¢†åŸŸçš„ä¸€æ¬¡é‡è¦çªç ´ã€‚è¿™ä¸€ä¸­å‹å‚æ•°æ¨¡å‹ï¼Œå‡­å€Ÿå…¶å“è¶Šçš„æ€§èƒ½å’Œå¤šæ ·åŒ–çš„åŠŸèƒ½ï¼Œè¿…é€Ÿå¸å¼•äº†ä¸šç•Œçš„å¹¿æ³›å…³æ³¨ã€‚

### **æœ¬ç¯‡ç¬”è®°æ‰€å¯¹åº”çš„è§†é¢‘ï¼š**

- [ğŸ‘‰ğŸ‘‰ğŸ‘‰ é€šè¿‡å“”å“©å“”å“©è§‚çœ‹](https://www.bilibili.com/video/BV1BZF5e8E6z/)
- [ğŸ‘‰ğŸ‘‰ğŸ‘‰ é€šè¿‡YouTubeè§‚çœ‹](https://youtu.be/hhFZW7r-ySU)
- [ğŸ‘‰ğŸ‘‰ğŸ‘‰ æˆ‘çš„å¼€æºé¡¹ç›®](https://github.com/win4r/AISuperDomain)
- [ğŸ‘‰ğŸ‘‰ğŸ‘‰ è¯·æˆ‘å–å’–å•¡](https://ko-fi.com/aila)
- ğŸ‘‰ğŸ‘‰ğŸ‘‰ æˆ‘çš„å¾®ä¿¡ï¼šstoeng ã€åŠ æˆ‘è¯·æ³¨æ˜æ¥æ„ã€‘
- ğŸ‘‰ğŸ‘‰ğŸ‘‰ æ‰¿æ¥å¤§æ¨¡å‹å¾®è°ƒã€RAGã€AIæ™ºèƒ½ä½“ã€AIç›¸å…³åº”ç”¨å¼€å‘ç­‰é¡¹ç›®ã€‚


## ğŸš€ç®€ä»‹

### å¼ºå¤§çš„è§†è§‰ç†è§£èƒ½åŠ›

Qwen2.5-VL-7B-Instructä¸ä»…èƒ½å¤Ÿè¯†åˆ«èŠ±ã€é¸Ÿã€é±¼ç­‰å¸¸è§ç‰©ä½“ï¼Œè¿˜å…·æœ‰æå¼ºçš„æ–‡æœ¬ã€å›¾è¡¨ã€å›¾æ ‡åŠå›¾å½¢çš„ç†è§£èƒ½åŠ›ã€‚é€šè¿‡æ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿå…¨é¢è§£æå›¾åƒå†…å®¹ï¼Œå°†è§†è§‰ä¿¡æ¯è½¬åŒ–ä¸ºå¯ä»¥ç†è§£å’Œæ“ä½œçš„ç»“æ„åŒ–æ•°æ®ã€‚è¿™ä½¿å¾—Qwen2.5-VL-7B-Instructèƒ½å¤Ÿé€‚åº”æ›´åŠ å¤æ‚çš„è§†è§‰ä»»åŠ¡ï¼Œæˆä¸ºè¯¸å¦‚å›¾åƒæ ‡æ³¨ã€ç‰©ä½“è¯†åˆ«ç­‰åº”ç”¨åœºæ™¯ä¸­çš„ç†æƒ³é€‰æ‹©ã€‚

### è§†è§‰ä»£ç†ä¸æ™ºèƒ½æ¨ç†

Qwen2.5-VL-7B-Instructçš„å¦ä¸€å¤§äº®ç‚¹åœ¨äºå…¶ä½œä¸ºè§†è§‰ä»£ç†çš„èƒ½åŠ›ã€‚é€šè¿‡æ™ºèƒ½æ¨ç†ï¼Œæ¨¡å‹èƒ½å¤ŸåŠ¨æ€åœ°ä½¿ç”¨å„ç§å·¥å…·è¿›è¡Œä»»åŠ¡å¤„ç†ï¼Œåˆæ­¥å…·å¤‡äº†æ¨¡æ‹Ÿäººç±»æ“ä½œè®¾å¤‡çš„èƒ½åŠ›ã€‚æ— è®ºæ˜¯æ“ä½œç”µè„‘è¿˜æ˜¯æ‰‹æœºï¼ŒQwen2.5-VL-7B-Instructå‡èƒ½å±•ç°å‡ºå¼ºå¤§çš„é€‚åº”æ€§å’Œçµæ´»æ€§ï¼Œè¿›ä¸€æ­¥æå‡äº†æ¨¡å‹çš„å®ç”¨æ€§å’Œäº’åŠ¨æ€§ã€‚

### é•¿è§†é¢‘ç†è§£ä¸äº‹ä»¶æ•æ‰

ä¸è®¸å¤šåŒç±»æ¨¡å‹ç›¸æ¯”ï¼ŒQwen2.5-VL-7B-Instructåœ¨å¤„ç†é•¿æ—¶é—´è§†é¢‘æ–¹é¢å±•ç°äº†å…¶ç‹¬ç‰¹ä¼˜åŠ¿ã€‚è¯¥æ¨¡å‹ä¸ä»…å¯ä»¥ç†è§£è¶…è¿‡ä¸€å°æ—¶çš„é•¿è§†é¢‘ï¼Œè¿˜èƒ½å¤Ÿç²¾å‡†å®šä½è§†é¢‘ä¸­çš„å…³é”®ç‰‡æ®µï¼Œå¸®åŠ©ç”¨æˆ·å¿«é€Ÿæ•æ‰é‡è¦äº‹ä»¶ã€‚è¿™ä¸€åŠŸèƒ½çš„å®ç°ï¼Œä½¿å¾—Qwen2.5-VL-7B-Instructåœ¨è§†é¢‘åˆ†æã€æ–°é—»ç›‘æ§ç­‰é¢†åŸŸå±•ç°å‡ºå·¨å¤§çš„æ½œåŠ›ã€‚

### ç²¾ç¡®çš„è§†è§‰å®šä½ä¸ç»“æ„åŒ–è¾“å‡º

Qwen2.5-VL-7B-Instructåœ¨è§†è§‰å®šä½æ–¹é¢ä¹Ÿæœ‰ä¸å°çš„çªç ´ã€‚æ¨¡å‹èƒ½å¤Ÿé€šè¿‡ç”Ÿæˆè¾¹ç•Œæ¡†æˆ–åæ ‡ç‚¹ï¼Œå‡†ç¡®åœ°å®šä½å›¾åƒä¸­çš„ç‰©ä½“ï¼Œå¹¶ä¸ºå±æ€§æä¾›ç¨³å®šçš„JSONè¾“å‡ºã€‚è¿™ä¸€æŠ€æœ¯çš„å®ç°ï¼Œä½¿å¾—Qwen2.5-VL-7B-Instructåœ¨å›¾åƒå¤„ç†ã€è‡ªåŠ¨æ ‡æ³¨å’Œæ•°æ®æå–ç­‰ä»»åŠ¡ä¸­å±•ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ã€‚

æ­¤å¤–ï¼ŒQwen2.5-VL-7B-Instructåœ¨å¤„ç†ç»“æ„åŒ–æ•°æ®ï¼ˆå¦‚å‘ç¥¨ã€è¡¨å•ã€è¡¨æ ¼ç­‰ï¼‰æ—¶ï¼Œèƒ½å¤Ÿè‡ªåŠ¨æå–å¹¶ç”Ÿæˆç»“æ„åŒ–è¾“å‡ºï¼Œå¹¿æ³›åº”ç”¨äºé‡‘èã€å•†ä¸šç­‰å¤šä¸ªé¢†åŸŸï¼Œæå¤§æå‡äº†æ•°æ®å¤„ç†çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

### æ€§èƒ½æå‡ä¸æ¶æ„ä¼˜åŒ–

ä¸ä¸Šä¸€ä»£Qwen2-VLç›¸æ¯”ï¼ŒQwen2.5-VLç³»åˆ—åœ¨æ¨¡å‹æ¶æ„ä¸Šè¿›è¡Œäº†é‡è¦ä¼˜åŒ–ï¼Œç®€åŒ–äº†ç½‘ç»œç»“æ„å¹¶å¢å¼ºäº†æ¨¡å‹å¯¹æ—¶é—´å’Œç©ºé—´å°ºåº¦çš„æ„ŸçŸ¥èƒ½åŠ›ã€‚è¿™ä¸€æ”¹è¿›ä¸ä»…æå‡äº†Qwen2.5-VL-7B-Instructçš„è¿è¡Œæ•ˆç‡ï¼Œè¿˜ä½¿å…¶åœ¨å¤šä¸ªè§†è§‰è¯­è¨€ä»»åŠ¡ä¸­è¶…è¶Šäº†åŒç±»äº§å“ï¼Œå¦‚GPT-4o-miniã€‚

### å¼€æºä¸å¹¿æ³›åº”ç”¨

Qwen2.5-VL-7B-Instructç›®å‰å·²åœ¨Hugging Faceã€ModelScopeç­‰å¹³å°å¼€æºï¼Œç”¨æˆ·å¯ä»¥æ ¹æ®è‡ªèº«éœ€æ±‚è¿›è¡Œä¸‹è½½å’Œä½¿ç”¨ã€‚é€šè¿‡å¼€æºï¼Œé˜¿é‡Œå·´å·´é€šä¹‰åƒé—®å›¢é˜Ÿä¸ºæ›´å¤šå¼€å‘è€…æä¾›äº†æ¢ç´¢å’Œåº”ç”¨è¿™ä¸€æ¨¡å‹çš„æœºä¼šï¼Œè¿›ä¸€æ­¥æ¨åŠ¨äº†è§†è§‰è¯­è¨€ç†è§£é¢†åŸŸçš„å‘å±•ã€‚

### ğŸš€æœ¬åœ°éƒ¨ç½²å‘½ä»¤(é€šè¿‡historyå‘½ä»¤æ˜¾ç¤ºæˆ‘æ‰€è¾“å…¥çš„å‘½ä»¤)ï¼š

```bash
(qwen_vl) Ubuntu@0017-dsm-prxmx30138:~$ history 20
    8  conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia
    9  pip install git+https://github.com/huggingface/transformers accelerate
   10  pip install beautifulsoup4 tinycss2
   11  pip install six
   12  pip install "qwen-vl-utils[decord]==0.0.8"
   13  pip install git+https://github.com/huggingface/transformers accelerate
   14  clear
   15  pip install "qwen-vl-utils[decord]==0.0.8"
   16  clear
   17  nano app.py
   18  python app.py
   19  clear
   20  python app.py
   21  pip install gradio
   22  clear
   23  python app.py
   24  clear
   25  history 20  # æ˜¾ç¤ºæœ€è¿‘20æ¡å‘½ä»¤
```

### ğŸš€è§†é¢‘ä¸­æ‰€ç”¨åˆ°çš„ä»£ç ï¼š

```bash
import gradio as gr
from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor
from qwen_vl_utils import process_vision_info
import torch

# åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨
model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
    "Qwen/Qwen2.5-VL-7B-Instruct", 
    torch_dtype="auto", 
    device_map="auto"
)
processor = AutoProcessor.from_pretrained("Qwen/Qwen2.5-VL-7B-Instruct")

def process_image_and_text(image, text_prompt):
    if image is None:
        return "è¯·ä¸Šä¼ ä¸€å¼ å›¾ç‰‡ã€‚"
    
    # æ„å»ºæ¶ˆæ¯æ ¼å¼
    messages = [
        {
            "role": "user",
            "content": [
                {
                    "type": "image",
                    "image": image,  # Gradioå°†è‡ªåŠ¨å¤„ç†å›¾ç‰‡è·¯å¾„
                },
                {"type": "text", "text": text_prompt if text_prompt else "Describe this image."},
            ],
        }
    ]
    
    try:
        # å‡†å¤‡æ¨ç†è¾“å…¥
        text = processor.apply_chat_template(
            messages, tokenize=False, add_generation_prompt=True
        )
        image_inputs, video_inputs = process_vision_info(messages)
        inputs = processor(
            text=[text],
            images=image_inputs,
            videos=video_inputs,
            padding=True,
            return_tensors="pt",
        )
        inputs = inputs.to(model.device)

        # ç”Ÿæˆè¾“å‡º
        with torch.no_grad():
            generated_ids = model.generate(**inputs, max_new_tokens=128)
            generated_ids_trimmed = [
                out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
            ]
            output_text = processor.batch_decode(
                generated_ids_trimmed, 
                skip_special_tokens=True, 
                clean_up_tokenization_spaces=False
            )
        
        return output_text[0]
    
    except Exception as e:
        return f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}"

# åˆ›å»ºGradioç•Œé¢
with gr.Blocks() as demo:
    gr.Markdown("# Qwen2.5-VL å›¾åƒç†è§£æ¼”ç¤º")
    
    with gr.Row():
        with gr.Column():
            image_input = gr.Image(type="filepath", label="ä¸Šä¼ å›¾ç‰‡")
            text_input = gr.Textbox(
                placeholder="è¯·è¾“å…¥æç¤ºè¯­ï¼ˆå¦‚ä¸è¾“å…¥ï¼Œé»˜è®¤æè¿°å›¾ç‰‡ï¼‰", 
                label="æç¤ºè¯­"
            )
            submit_btn = gr.Button("æäº¤")
        
        with gr.Column():
            output = gr.Textbox(label="è¾“å‡ºç»“æœ")
    
    submit_btn.click(
        fn=process_image_and_text,
        inputs=[image_input, text_input],
        outputs=output
    )

    gr.Examples(
        examples=[
            ["path/to/example1.jpg", "è¿™å¼ å›¾ç‰‡é‡Œæœ‰ä»€ä¹ˆï¼Ÿ"],
            ["path/to/example2.jpg", "æè¿°å›¾ä¸­çš„åœºæ™¯"],
        ],
        inputs=[image_input, text_input],
    )

# å¯åŠ¨åº”ç”¨
if __name__ == "__main__":
    demo.launch(share=True)
```