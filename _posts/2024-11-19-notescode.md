---
layout: single
title: "ç«¯è„‘äº‘ç¬”è®°ä»£ç "
sidebar:
  nav: "docs"
date: 2024-11-19 00:00:00 +0800
categories: [AI-Agents, LLM]
tags: [AI, AI-Agents, AutoGen, LLM, Llama-3, Qwen]
classes: wide
author_profile: true
---


#  ç«¯è„‘äº‘ç¬”è®°ä»£ç  

###  é‚€è¯·é“¾æ¥ 

[ https://cephalon.cloud/#/share/register-landing?id=rjFrw9 ](<https://cephalon.cloud/#/share/register-landing?id=rjFrw9>)

###  æ¥å£ç¤ºä¾‹ 
    
    
```
    curl --request POST 'https://cephalon.cloud/user-center/v1/model/chat/completions' \
    --header 'Content-Type: application/json' \
    --header 'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJJbmZvIjoiYXBpOjE4NTUwMzg0MjE2MTY3NTQ2ODgiLCJleHAiOjE3NjM0NDg1OTd9.POWZI5rv8bu6_aM-2CHfUhRxJP6nZRIoaF66ci_BTAc' \
    --header 'Accept: */*' \
    --header 'Connection: keep-alive' \
    --data-raw '{
    "model": "Llama-3.1-70B-Instruct",
    "messages": [
    {
      "role": "system",
      "content": "You are a helpful assistant."
    },
    {
      "role": "user",
      "content": "Hello!"
    }
    ],
    "stream": true
     }'
```
    

###  autogenä»£ç  
    
    
    !pip install autogen-agentchat~=0.2
    
```
    import os
    from autogen import AssistantAgent, UserProxyAgent
    from google.colab import userdata
```
    
```
    # ä»Google Colabçš„userdataä¸­è·å–API key
    # éœ€è¦åœ¨Colabä¸­é¢„å…ˆè®¾ç½®CEPHALON_API_KEY
    try:
        API_KEY = userdata.get('CEPHALON_API_KEY')
        if not API_KEY:
            raise ValueError("CEPHALON_API_KEYæœªåœ¨Colabä¸­è®¾ç½®")
    except Exception as e:
        raise ValueError("æ— æ³•ä»Colabè·å–API keyã€‚è¯·ç¡®ä¿ä»£ç åœ¨Colabç¯å¢ƒä¸­è¿è¡Œï¼Œå¹¶ä¸”å·²è®¾ç½®CEPHALON_API_KEY") from e
```
    
```
    # LLMé…ç½®
    # config_list: åŒ…å«æ¨¡å‹é…ç½®çš„åˆ—è¡¨
    # model: ä½¿ç”¨çš„æ¨¡å‹åç§°
    # api_key: ä»Colab userdataè·å–çš„APIå¯†é’¥
    # base_url: APIæœåŠ¡å™¨åœ°å€
    llm_config = {
        "config_list": [{
            "model": "Llama-3.1-70B-Instruct",  # ä½¿ç”¨Llama 3.1 70BæŒ‡ä»¤æ¨¡å‹
            "api_key": API_KEY,                  # ä»Colab userdataè·å–çš„API key
            "base_url": "https://cephalon.cloud/user-center/v1/model"  # APIç«¯ç‚¹
        }]
    }
```
    
```
    # åˆ›å»ºAssistantä»£ç†
    # AssistantAgent: èƒ½å¤Ÿå›ç­”é—®é¢˜å’Œæ‰§è¡Œä»»åŠ¡çš„AIåŠ©æ‰‹
    assistant = AssistantAgent("assistant", llm_config=llm_config)
```
    
```
    # åˆ›å»ºUserProxyä»£ç†
    # UserProxyAgent: ä»£è¡¨ç”¨æˆ·ä¸Assistantäº¤äº’çš„ä»£ç†
    # code_execution_config=False è¡¨ç¤ºç¦ç”¨ä»£ç æ‰§è¡ŒåŠŸèƒ½
    user_proxy = UserProxyAgent("user_proxy", code_execution_config=False)
```
    
```
    # å¯åŠ¨å¯¹è¯
    # å‘åŠ©æ‰‹æå‡ºæ•°å­¦é—®é¢˜ï¼šè®¡ç®—179424673æ˜¯ç¬¬å‡ ä¸ªè´¨æ•°
    user_proxy.initiate_chat(
        assistant,
        message="è®¡ç®—179424673æ˜¯ç¬¬å‡ ä¸ªè´¨æ•°.",
    )
```
    
    
    #-----------------------------
    
```
    import os
    from autogen import ConversableAgent
    from google.colab import userdata
```
    
    API_KEY = userdata.get('CEPHALON_API_KEY')
    
```
    # ä¸ºæŠ€æœ¯ä¸“å®¶é…ç½®Llamaæ¨¡å‹
    llm_config_expert = {
        "config_list": [
            {
                "model": "Llama-3.1-70B-Instruct",  # æŠ€æœ¯ä¸“å®¶ä½¿ç”¨Llamaæ¨¡å‹
                "api_key": API_KEY,
                "base_url": "https://cephalon.cloud/user-center/v1/model"
            }
        ]
    }
```
    
```
    # ä¸ºä¼ä¸šé¡¾é—®é…ç½®Qwenæ¨¡å‹
    llm_config_consultant = {
        "config_list": [
            {
                "model": "Qwen2.5-72B-Instruct-AWQ",  # ä¼ä¸šé¡¾é—®ä½¿ç”¨Qwenæ¨¡å‹
                "api_key": API_KEY,
                "base_url": "https://cephalon.cloud/user-center/v1/model"
            }
        ]
    }
```
    
    
```
    # åˆ›å»ºæŠ€æœ¯ä¸“å®¶ä»£ç†
    expert = ConversableAgent(
        name="expert",
        system_message="ä½ æ˜¯ä¸€ä½äººå·¥æ™ºèƒ½æŠ€æœ¯ä¸“å®¶ï¼Œä¸“æ³¨äºå¤§è¯­è¨€æ¨¡å‹çš„æŠ€æœ¯å®ç°å’Œéƒ¨ç½²æ¶æ„ã€‚ä½ æ“…é•¿è§£é‡ŠæŠ€æœ¯ç»†èŠ‚ï¼Œå¹¶èƒ½æä¾›å…·ä½“çš„å®æ–½å»ºè®®ã€‚",
        llm_config=llm_config_expert,
        human_input_mode="NEVER",
    )
```
    
```
    # åˆ›å»ºä¼ä¸šé¡¾é—®ä»£ç†
    consultant = ConversableAgent(
        name="consultant",
        system_message="ä½ æ˜¯ä¸€ä½ä¼ä¸šæ•°å­—åŒ–è½¬å‹é¡¾é—®ï¼Œæ“…é•¿åˆ†æå¤§è¯­è¨€æ¨¡å‹åœ¨ä¸åŒè¡Œä¸šçš„åº”ç”¨åœºæ™¯å’Œå•†ä¸šä»·å€¼ã€‚ä½ å…³æ³¨ROIå’Œå®é™…è½åœ°æ•ˆæœã€‚",
        llm_config=llm_config_consultant,
        human_input_mode="NEVER",
    )
```
    
    
```
    # å¯åŠ¨å¯¹è¯
    result = consultant.initiate_chat(
        expert,
        message="ä½œä¸ºæŠ€æœ¯ä¸“å®¶ï¼Œä½ è®¤ä¸ºå¤§è¯­è¨€æ¨¡å‹åœ¨ä¼ä¸šç¯å¢ƒä¸­æœ€å…·æ½œåŠ›çš„ä¸‰ä¸ªåº”ç”¨åœºæ™¯æ˜¯ä»€ä¹ˆï¼Ÿè¯·ä»æŠ€æœ¯å¯è¡Œæ€§å’Œè½åœ°éš¾åº¦çš„è§’åº¦è¿›è¡Œåˆ†æã€‚",
        max_turns=4  # å¢åŠ å¯¹è¯è½®æ¬¡ä»¥ä¾¿æ›´æ·±å…¥è®¨è®º
    )
```
    
    
```
    #---------------------
    import os
    from autogen import AssistantAgent, UserProxyAgent, GroupChat, GroupChatManager
    from google.colab import userdata
```
    
```
    # ä»Google Colabçš„userdataä¸­è·å–API key
    try:
        API_KEY = userdata.get('CEPHALON_API_KEY')
        if not API_KEY:
            raise ValueError("CEPHALON_API_KEYæœªåœ¨Colabä¸­è®¾ç½®")
    except Exception as e:
        raise ValueError("æ— æ³•ä»Colabè·å–API keyã€‚è¯·ç¡®ä¿ä»£ç åœ¨Colabç¯å¢ƒä¸­è¿è¡Œï¼Œå¹¶ä¸”å·²è®¾ç½®CEPHALON_API_KEY") from e
```
    
```
    # LLMé…ç½®
    llm_config = {
        "config_list": [{
            "model": "Llama-3.1-70B-Instruct",  # ä½¿ç”¨Llama 3.1 70BæŒ‡ä»¤æ¨¡å‹
            "api_key": API_KEY,                  # ä»Colab userdataè·å–çš„API key
            "base_url": "https://cephalon.cloud/user-center/v1/model"  # APIç«¯ç‚¹
        }]
    }
```
    
```
    # åˆ›å»ºç”¨æˆ·ä»£ç†
    user_proxy = UserProxyAgent(
        name="ä¼ä¸šå†³ç­–è€…",
        system_message="ä½œä¸ºä¼ä¸šå†³ç­–è€…ï¼Œå…³æ³¨å¤§æ¨¡å‹åœ¨ä¼ä¸šä¸­çš„å®é™…åº”ç”¨ä»·å€¼å’Œè½åœ°å¯èƒ½æ€§ã€‚",
        code_execution_config={
            "last_n_messages": 2,
            "work_dir": "enterprise_chat",
            "use_docker": False,
        },
        human_input_mode="TERMINATE"
    )
```
    
```
    # åˆ›å»ºæŠ€æœ¯ä¸“å®¶ä»£ç†
    tech_expert = AssistantAgent(
        name="æŠ€æœ¯ä¸“å®¶",
        system_message="ä½œä¸ºAIæŠ€æœ¯ä¸“å®¶ï¼Œä¸“æ³¨äºå¤§æ¨¡å‹æŠ€æœ¯å®ç°ã€éƒ¨ç½²æ¶æ„å’Œæ€§èƒ½ä¼˜åŒ–ç­‰æŠ€æœ¯ç»†èŠ‚ã€‚",
        llm_config=llm_config,
    )
```
    
```
    # åˆ›å»ºå•†ä¸šåˆ†æå¸ˆä»£ç†
    business_analyst = AssistantAgent(
        name="å•†ä¸šåˆ†æå¸ˆ",
        system_message="ä½œä¸ºå•†ä¸šåˆ†æå¸ˆï¼Œå…³æ³¨å¤§æ¨¡å‹åº”ç”¨çš„å•†ä¸šä»·å€¼ã€æŠ•èµ„å›æŠ¥å’Œå¸‚åœºæœºä¼šã€‚",
        llm_config=llm_config,
    )
```
    
```
    # åˆ›å»ºé£æ§ä¸“å®¶ä»£ç†
    risk_expert = AssistantAgent(
        name="é£æ§ä¸“å®¶",
        system_message="ä½œä¸ºé£æ§ä¸“å®¶ï¼Œå…³æ³¨å¤§æ¨¡å‹åº”ç”¨ä¸­çš„æ•°æ®å®‰å…¨ã€éšç§ä¿æŠ¤å’Œåˆè§„é£é™©ã€‚",
        llm_config=llm_config,
    )
```
    
```
    # åˆ›å»ºç¾¤èŠ
    groupchat = GroupChat(
        agents=[user_proxy, tech_expert, business_analyst, risk_expert],
        messages=[],
        max_round=4
    )
```
    
    # åˆ›å»ºç¾¤èŠç®¡ç†å™¨
    manager = GroupChatManager(groupchat=groupchat, llm_config=llm_config)
    
```
    # å¯åŠ¨è®¨è®º
    discussion_topic = """
    æˆ‘ä»¬æ­£åœ¨è€ƒè™‘åœ¨ä¼ä¸šä¸­éƒ¨ç½²å¤§æ¨¡å‹åº”ç”¨ï¼Œéœ€è¦è®¨è®ºä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š
    1. æŠ€æœ¯æ¶æ„é€‰å‹ï¼ˆè‡ªå»ºè¿˜æ˜¯ä½¿ç”¨APIæœåŠ¡ï¼‰
    2. åº”ç”¨åœºæ™¯è¯†åˆ«å’Œä¼˜å…ˆçº§æ’åº
    3. æ•°æ®å®‰å…¨å’Œéšç§ä¿æŠ¤æ–¹æ¡ˆ
    4. æŠ•èµ„é¢„ç®—å’ŒROIåˆ†æ
    è¯·å„ä½ä¸“å®¶ä»å„è‡ªä¸“ä¸šè§’åº¦è¿›è¡Œåˆ†æå’Œå»ºè®®ã€‚
    """
```
    
```
    user_proxy.initiate_chat(
        manager,
        message=discussion_topic
    )
    # è¾“å…¥exitå¯ç»ˆæ­¢å¯¹è¯
```
    
    
    
    

##  **ğŸ‘‰ğŸ‘‰ğŸ‘‰å¦‚æœ‰é—®é¢˜è¯·è”ç³»æˆ‘çš„å¾½ä¿¡ stoeng**

# 

## 
