---
layout: single
title: "Metaæœ€æ–°å¤šæ¨¡æ€æ¨¡å‹Llama3.2éœ‡æ’¼å‘å¸ƒ!90Bå‚æ•°"
sidebar:
  nav: "docs"
date: 2024-09-27 00:00:00 +0800
categories: [Fine-Tuning, LLM, RAG, Vision]
tags: [AI, Claude, HuggingFace, LLM, Llama-3, Ollama, Vision]
classes: wide
author_profile: true
---


#  Metaæœ€æ–°å¤šæ¨¡æ€æ¨¡å‹Llama3.2éœ‡æ’¼å‘å¸ƒ!90Bå‚æ•° 

###  æœ¬åœ°å®‰è£… 
    
    
    ollama run llama3.2:3b
    
    
    
    ###vLLMæŒ‰ç…§æ­¥éª¤
    
    pip install -U "huggingface_hub[cli]"
    
    huggingface-cli login
    
    pip install --upgrade vllm
    
    echo 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/extras/CUPTI/lib64/' >> ~/.bashrc
    source ~/.bashrc
    
    
```
    vllm serve meta-llama/Llama-3.2-11B-Vision \
        --tokenizer meta-llama/Llama-3.2-11B-Vision-Instruct \
        --tokenizer-mode auto \
        --limit_mm_per_prompt 'image=4' \
        --max_num_batched_tokens 65536 \
        --gpu-memory-utilization 0.95 \
        --max-model-len 65536 \
        --trust-remote-code
```
    
    
    
    
    

##  **ğŸ‘‰ğŸ‘‰ğŸ‘‰å¦‚æœ‰é—®é¢˜è¯·è”ç³»æˆ‘çš„å¾½ä¿¡ stoeng**

##  **ğŸ”¥ğŸ”¥ğŸ”¥æœ¬é¡¹ç›®ä»£ç ç”±AIè¶…å…ƒåŸŸé¢‘é“åˆ¶ä½œï¼Œè§‚çœ‹æ›´å¤šå¤§æ¨¡å‹å¾®è°ƒè§†é¢‘è¯·è®¿é—®æˆ‘çš„é¢‘é“â¬‡**

###  **ğŸ‘‰ğŸ‘‰ğŸ‘‰** **[ æˆ‘çš„å“”å“©å“”å“©é¢‘é“ ](<https://space.bilibili.com/3493277319825652>) **

###  **ğŸ‘‰ğŸ‘‰ğŸ‘‰** **[ æˆ‘çš„YouTubeé¢‘é“ ](<https://www.youtube.com/@AIsuperdomain>) **

###  **ğŸ‘‰ğŸ‘‰ğŸ‘‰æˆ‘çš„å¼€æºé¡¹ç›®** **[ https://github.com/win4r/AISuperDomain ](<https://github.com/win4r/AISuperDomain>) **

###  API 
    
    
```
    import requests
    import base64
    import json
```
    
    invoke_url = "https://ai.api.nvidia.com/v1/gr/meta/llama-3.2-90b-vision-instruct/chat/completions"
    stream = False
    
    with open("6.jpeg", "rb") as f:
        image_b64 = base64.b64encode(f.read()).decode()
    
    assert len(image_b64) < 180_000, \
        "To upload larger images, use the assets API (see docs)"
    
```
    headers = {
        "Authorization": "Bearer nvapi-xxx-Hnp-vG",
        "Accept": "application/json"
    }
```
    
```
    payload = {
        "model": 'meta/llama-3.2-90b-vision-instruct',
        "messages": [
            {
                "role": "user",
                "content": f'What is in this image? <img src="data:image/png;base64,{image_b64}" />'
            }
        ],
        "max_tokens": 512,
        "temperature": 1.00,
        "top_p": 1.00,
        "stream": stream
    }
```
    
    response = requests.post(invoke_url, headers=headers, json=payload)
    
```
    if response.status_code == 200:
        response_json = response.json()
        image_description = response_json['choices'][0]['message']['content']
        print(image_description)
    else:
        print(f"Error: {response.status_code}")
        print(response.text)
```

###  åœ¨çº¿æµ‹è¯• 

[ https://build.nvidia.com/meta/llama-3.2-90b-vision-instruct ](<https://build.nvidia.com/meta/llama-3.2-90b-vision-instruct>)

###  prompt 
    
    
    Where is the woman in the black and white striped top in the picture?
    
    
    Where is the man wearing a white shirt, light blue jeans, and white shoes in the picture?
    
    
    Extract the information from the invoice and place the extracted content into a table.
    
    
    Extract the text from the image while maintaining the original format.
    
    
    cè§†é¢‘ï¼š
    A woman wearing a red top and blue jeans
    
    dè§†é¢‘ï¼š
    A short-haired man wearing blue jeans and a black shirt with green sleeves
    
    
    
    
    
    
    
    
    
    
    
    

Llama 3.2 æ˜¯Metaå…¬å¸æœ€æ–°å‘å¸ƒçš„å¤šæ¨¡æ€äººå·¥æ™ºèƒ½æ¨¡å‹ç³»åˆ—ï¼Œæ—¨åœ¨æå‡å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨è§†è§‰ç†è§£å’Œè¾¹ç¼˜è®¡ç®—é¢†åŸŸã€‚è¯¥ç³»åˆ—æ¨¡å‹äº2024å¹´9æœˆ25æ—¥æ­£å¼æ¨å‡ºï¼ŒåŒ…å«å¤šç§ä¸åŒè§„æ¨¡çš„æ¨¡å‹ï¼Œé€‚ç”¨äºå„ç§åº”ç”¨åœºæ™¯ã€‚ 

##  **æ¨¡å‹æ¦‚è¿°**

Llama 3.2 ç³»åˆ—åŒ…æ‹¬ä»¥ä¸‹å‡ ç§æ¨¡å‹ï¼š 

  * **Llama 3.2 90B Vision** ï¼šæ”¯æŒæ–‡æœ¬å’Œå›¾åƒè¾“å…¥ï¼Œé€‚åˆä¼ä¸šçº§åº”ç”¨ï¼Œæ“…é•¿å¸¸è¯†æ¨ç†ã€é•¿æ–‡æœ¬ç”Ÿæˆå’Œå¤šè¯­è¨€ç¿»è¯‘ç­‰ä»»åŠ¡ã€‚ 


  * **Llama 3.2 11B Vision** ï¼šåŒæ ·æ”¯æŒæ–‡æœ¬å’Œå›¾åƒè¾“å…¥ï¼Œé€‚åˆå†…å®¹åˆ›å»ºå’Œå¯¹è¯å¼äººå·¥æ™ºèƒ½åº”ç”¨ï¼Œå…·å¤‡å›¾åƒæ¨ç†èƒ½åŠ›ã€‚ 


  * **Llama 3.2 3B** ï¼šä¸“ä¸ºä½å»¶è¿Ÿæ¨ç†å’Œæœ‰é™è®¡ç®—èµ„æºè®¾è®¡ï¼Œé€‚åˆæ–‡æœ¬æ‘˜è¦ã€åˆ†ç±»å’Œè¯­è¨€ç¿»è¯‘ç­‰ä»»åŠ¡ã€‚ 


  * **Llama 3.2 1B** ï¼šæœ€è½»é‡çº§çš„æ¨¡å‹ï¼Œéå¸¸é€‚åˆè¾¹ç¼˜è®¾å¤‡å’Œç§»åŠ¨åº”ç”¨ç¨‹åºçš„æ–‡æœ¬æ£€ç´¢å’Œæ‘˜è¦ã€‚ 


æ‰€æœ‰æ¨¡å‹å‡æ”¯æŒé«˜è¾¾128Kä¸ªtokençš„ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œè¿™å¯¹äºéœ€è¦å¤„ç†å¤§é‡ä¿¡æ¯çš„ä»»åŠ¡å°¤ä¸ºé‡è¦ 

ã€‚ 

##  **å¤šæ¨¡æ€åŠŸèƒ½**

Llama 3.2 çš„é‡è¦ç‰¹ç‚¹æ˜¯å…¶å¤šæ¨¡æ€èƒ½åŠ›ã€‚å®ƒèƒ½å¤ŸåŒæ—¶å¤„ç†æ–‡æœ¬ã€å›¾åƒå’Œè§†é¢‘ï¼Œä½¿å¾—ç”¨æˆ·å¯ä»¥åœ¨åŒä¸€äº¤äº’ä¸­ç»“åˆä¸åŒç±»å‹çš„å†…å®¹ã€‚è¿™ç§èƒ½åŠ›ä½¿å¾—æ¨¡å‹åœ¨å›¾åƒç†è§£ã€è§†è§‰æ¨ç†ç­‰ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä¸å…¶ä»–é¢†å…ˆçš„é—­æºæ¨¡å‹ï¼ˆå¦‚Claude 3 Haikuï¼‰ç›¸åª²ç¾ 

ã€‚ 

##  **æ¨¡å‹æ¶æ„ä¸è®­ç»ƒ**

Llama 3.2 åŸºäºä¹‹å‰ç‰ˆæœ¬ï¼ˆå¦‚Llama 3.1ï¼‰è¿›è¡Œäº†ä¼˜åŒ–ï¼Œé‡‡ç”¨äº†å…ˆè¿›çš„è½¬åŒ–å™¨æ¶æ„ã€‚æ¨¡å‹è®­ç»ƒåˆ†ä¸ºå¤šä¸ªé˜¶æ®µï¼š 

  1. **é¢„è®­ç»ƒé˜¶æ®µ** ï¼šåˆ©ç”¨å¤§è§„æ¨¡çš„å™ªå£°å›¾åƒ-æ–‡æœ¬å¯¹è¿›è¡Œåˆæ­¥è®­ç»ƒï¼Œç„¶ååœ¨ä¸­ç­‰è§„æ¨¡çš„é«˜è´¨é‡é¢†åŸŸæ•°æ®ä¸Šè¿›è¡Œè¿›ä¸€æ­¥è®­ç»ƒã€‚ 


  2. **åæœŸè®­ç»ƒé˜¶æ®µ** ï¼šé€šè¿‡ç›‘ç£å¾®è°ƒã€æ‹’ç»é‡‡æ ·å’Œç›´æ¥åå¥½ä¼˜åŒ–ç­‰æŠ€æœ¯è¿›è¡Œå¤šè½®å¯¹é½ï¼Œä»¥æé«˜æ¨¡å‹çš„å“åº”è´¨é‡å’Œå®‰å…¨æ€§ã€‚ 


æ­¤å¤–ï¼ŒLlama 3.2 è¿˜å¼•å…¥äº†çŸ¥è¯†è’¸é¦æŠ€æœ¯ï¼Œä½¿å¾—å°å‹æ¨¡å‹èƒ½å¤Ÿå€ŸåŠ©å¤§å‹æ¨¡å‹çš„è¾“å‡ºæå‡æ€§èƒ½ï¼Œè€Œä¸æ˜¯ä»é›¶å¼€å§‹å­¦ä¹  

ã€‚ 

##  **åº”ç”¨åœºæ™¯ä¸ä¼˜åŒ–**

Llama 3.2 çš„è®¾è®¡ç›®æ ‡æ˜¯æ»¡è¶³è¾¹ç¼˜è®¾å¤‡å’Œç§»åŠ¨åº”ç”¨çš„éœ€æ±‚ã€‚å®ƒåœ¨é«˜é€šå’Œè”å‘ç§‘ç¡¬ä»¶ä¸Šè¿›è¡Œäº†ä¼˜åŒ–ï¼Œä½¿å¾—è¿™äº›è½»é‡çº§æ¨¡å‹èƒ½å¤Ÿåœ¨èµ„æºæœ‰é™çš„ç¯å¢ƒä¸­é«˜æ•ˆè¿è¡Œã€‚å…·ä½“åº”ç”¨åœºæ™¯åŒ…æ‹¬ï¼š 

  * ç§»åŠ¨äººå·¥æ™ºèƒ½å†™ä½œåŠ©æ‰‹ 


  * å®¢æˆ·æœåŠ¡åº”ç”¨ 


  * å›¾åƒæ ‡é¢˜ç”Ÿæˆ 


  * æ–‡æ¡£è§†è§‰é—®é¢˜è§£ç­” 


å¼€å‘è€…å¯ä»¥åˆ©ç”¨Metaæä¾›çš„Llama Stack APIè¿›è¡Œå®šåˆ¶åŒ–å¼€å‘ï¼Œå¹¶é€šè¿‡torchtuneè¿›è¡Œå¾®è°ƒï¼Œä»¥é€‚åº”ä¸åŒçš„åº”ç”¨éœ€æ±‚ã€‚ 
