---
layout: single
title: "pixtral 12Bè½»æ¾å®ç°è§†é¢‘æ™ºèƒ½åˆ†æ"
sidebar:
  nav: "docs"
date: 2024-09-13 00:00:00 +0800
categories: [Fine-Tuning, LLM, Vision]
tags: [AI, Chainlit, HuggingFace, Mistral]
classes: wide
author_profile: true
---


#  pixtral 12Bè½»æ¾å®ç°è§†é¢‘æ™ºèƒ½åˆ†æ 

> Pixtral 12Bæ˜¯ç”±æ³•å›½åˆåˆ›å…¬å¸Mistral AIæœ€æ–°æ¨å‡ºçš„å¤šæ¨¡æ€äººå·¥æ™ºèƒ½æ¨¡å‹ã€‚è¿™ä¸ªæ¨¡å‹æ„ä¹‰é‡å¤§ï¼Œå› ä¸ºå®ƒä»£è¡¨äº†Mistralé¦–æ¬¡å°è¯•ç»“åˆæ–‡æœ¬å’Œå›¾åƒå¤„ç†èƒ½åŠ›ï¼Œä½¿å…¶æœ‰æœ›ä¸OpenAIå’ŒAnthropicç­‰å…¬å¸çš„é¢†å…ˆäººå·¥æ™ºèƒ½æ¨¡å‹å±•å¼€ç«äº‰ã€‚ 
> 
> ##  Pixtral 12Bçš„ä¸»è¦ç‰¹ç‚¹ 
> 
> **æ¨¡å‹æ¶æ„å’Œå‚æ•°**
> 
>   * **åŸºç¡€æ¨¡å‹** ï¼šåŸºäºä¹‹å‰å‘å¸ƒçš„æ–‡æœ¬æ¨¡å‹Nemo 12Bã€‚ 
> 

>   * **æ€»å‚æ•°é‡** ï¼šè·¨40å±‚å…±120äº¿å‚æ•°ã€‚ 
> 

>   * **è§†è§‰é€‚é…å™¨** ï¼šé›†æˆäº†4äº¿å‚æ•°çš„è§†è§‰é€‚é…å™¨ï¼Œå¢å¼ºäº†å¤„ç†è§†è§‰æ•°æ®çš„èƒ½åŠ›ã€‚ 
> 

>   * **éšè—ç»´åº¦** ï¼šå…·æœ‰14,336ä¸ªéšè—ç»´åº¦å’Œ32ä¸ªæ³¨æ„åŠ›å¤´ï¼Œå®ç°äº†å¹¿æ³›çš„è®¡ç®—å¤„ç†ã€‚ 
> 

>   * **å›¾åƒåˆ†è¾¨ç‡** ï¼šèƒ½å¤Ÿå¤„ç†1024 x 1024åƒç´ åˆ†è¾¨ç‡çš„å›¾åƒï¼Œå°†å…¶åˆ†å‰²æˆ16 x 16åƒç´ çš„å°å—ã€‚ 
> 

>   * **è¯å…ƒè¯æ±‡é‡** ï¼šæ‰©å±•äº†è¯æ±‡é‡è‡³131,072ä¸ªè¯å…ƒï¼ŒåŒ…æ‹¬ä¸‰ä¸ªæ–°çš„ä¸“ç”¨äºå›¾åƒå¤„ç†çš„ç‰¹æ®Šè¯å…ƒï¼š ` img ` ã€ ` img_break ` å’Œ ` img_end ` ã€‚ 
> 

>   * **ä½ç½®ç¼–ç ** ï¼šé‡‡ç”¨2D RoPEï¼ˆæ—‹è½¬ä½ç½®åµŒå…¥ï¼‰æ¥å¢å¼ºå¯¹å›¾åƒç©ºé—´å…³ç³»çš„ç†è§£ã€‚ 
> 

> 
> **åŠŸèƒ½**   
>  Pixtral 12Bå…è®¸ç”¨æˆ·é€šè¿‡URLæˆ–base64ç¼–ç è¾“å…¥å›¾åƒï¼Œèƒ½å¤Ÿæ‰§è¡Œå¤šç§ä»»åŠ¡ï¼Œå¦‚ï¼š   
> 
> 
>   * **å›¾åƒæè¿°** ï¼šä¸ºä¸Šä¼ çš„å›¾åƒç”Ÿæˆæè¿°æ€§æ–‡å­—ã€‚ 
> 

>   * **ç‰©ä½“è¯†åˆ«** ï¼šè¯†åˆ«å¹¶è®¡æ•°å›¾åƒä¸­çš„ç‰©ä½“ã€‚ 
> 

>   * **è§†è§‰é—®ç­”** ï¼šæ ¹æ®å›¾åƒå†…å®¹å›ç­”é—®é¢˜ã€‚ 
> 

> 
> è¯¥æ¨¡å‹çš„æ¶æ„æ”¯æŒåŒæ—¶å¤„ç†æ–‡æœ¬å’Œå›¾åƒï¼Œä½¿å…¶åœ¨å†…å®¹åˆ†æå’Œæ•°æ®è§£é‡Šæ–¹é¢çš„åº”ç”¨å…·æœ‰å¤šæ ·æ€§ã€‚ 
> 
> ##  å¯è®¿é—®æ€§å’Œè®¸å¯ 
> 
> Pixtral 12Bå¯é€šè¿‡GitHubå’ŒHugging Faceç­‰å¤šä¸ªå¹³å°ä¸‹è½½ï¼Œä¹Ÿå¯ä»¥é€šè¿‡ç£åŠ›é“¾æ¥è·å–ã€‚å®ƒä»¥Apache 2.0è®¸å¯è¯å‘å¸ƒï¼Œå…è®¸ç”¨æˆ·è‡ªç”±ä½¿ç”¨ã€ä¿®æ”¹å’Œå•†ä¸šåŒ–è¯¥æ¨¡å‹ã€‚ç„¶è€Œï¼Œç”¨äºè®­ç»ƒæ¨¡å‹çš„å…·ä½“æ•°æ®é›†å°šæœªå…¬å¼€ï¼Œè¿™å¼•å‘äº†å¯¹è®­ç»ƒæ•°æ®å¯èƒ½æ¶‰åŠçš„ç‰ˆæƒé—®é¢˜çš„è´¨ç–‘ã€‚æ­¤å¤–ï¼Œå…¶å®Œæ•´çš„è®¸å¯æ¡æ¬¾å°šæœªå®Œå…¨æ˜ç¡®ï¼Œé¢„è®¡æœªæ¥å°†æœ‰æ›´å¤šç›¸å…³ä¿¡æ¯å‘å¸ƒã€‚ 
> 
> ##  æœªæ¥å‘å±• 
> 
> Mistralè®¡åˆ’å°†Pixtral 12Bæ•´åˆåˆ°å…¶èŠå¤©æœºå™¨äººLe Chatå’ŒAPIå¹³å°La Platformeä¸­ï¼Œä½¿å¼€å‘è€…å’Œç”¨æˆ·æ›´å®¹æ˜“ä½¿ç”¨ã€‚éšç€äººå·¥æ™ºèƒ½ç¤¾åŒºå¼€å§‹è¯•éªŒPixtral 12Bï¼Œé¢„è®¡å°†ä¼šå¯¹å…¶èƒ½åŠ›å’Œæ€§èƒ½æœ‰æ›´æ·±å…¥çš„äº†è§£ã€‚ 
> 
> Pixtral 12Bæ ‡å¿—ç€Mistral AIåœ¨å¤šæ¨¡æ€äººå·¥æ™ºèƒ½é¢†åŸŸè¿ˆå‡ºäº†é‡è¦ä¸€æ­¥ï¼Œæœ‰æœ›å¢å¼ºç”Ÿæˆå¼äººå·¥æ™ºèƒ½åº”ç”¨çš„èƒ½åŠ›ã€‚è¿™ä¸ªæ¨¡å‹é€šè¿‡ç»“åˆå…ˆè¿›çš„æ–‡æœ¬å¤„ç†èƒ½åŠ›å’Œæ–°å¢çš„è§†è§‰å¤„ç†åŠŸèƒ½ï¼Œä¸ºç”¨æˆ·æä¾›äº†ä¸€ä¸ªå¼ºå¤§è€Œçµæ´»çš„å¤šæ¨¡æ€AIå·¥å…·ã€‚ 

###  ç¯å¢ƒ 

  * Ubuntu 


  * Nvidia RTX A6000*2 


  * vLLM 


##  **ğŸ‘‰ğŸ‘‰ğŸ‘‰å¦‚æœ‰é—®é¢˜è¯·è”ç³»æˆ‘çš„å¾½ä¿¡ stoeng**

##  **ğŸ”¥ğŸ”¥ğŸ”¥æœ¬é¡¹ç›®ä»£ç ç”±AIè¶…å…ƒåŸŸé¢‘é“åˆ¶ä½œï¼Œè§‚çœ‹æ›´å¤šå¤§æ¨¡å‹å¾®è°ƒè§†é¢‘è¯·è®¿é—®æˆ‘çš„é¢‘é“â¬‡**

###  **ğŸ‘‰ğŸ‘‰ğŸ‘‰** **[ æˆ‘çš„å“”å“©å“”å“©é¢‘é“ ](<https://space.bilibili.com/3493277319825652>) **

###  **ğŸ‘‰ğŸ‘‰ğŸ‘‰** **[ æˆ‘çš„YouTubeé¢‘é“ ](<https://www.youtube.com/@AIsuperdomain>) **

###  **ğŸ‘‰ğŸ‘‰ğŸ‘‰æˆ‘çš„å¼€æºé¡¹ç›®** **[ https://github.com/win4r/AISuperDomain ](<https://github.com/win4r/AISuperDomain>) **

###  å®‰è£… 
    
    
    pip install --upgrade mistral_common vllm
    
    
    vllm serve mistralai/Pixtral-12B-2409 --tokenizer_mode mistral --limit_mm_per_prompt 'image=4' --max_num_batched_tokens 16384 --gpu-memory-utilization 0.95 --max-model-len 65536
    
    vllm serve mistralai/Pixtral-12B-2409 --tokenizer_mode mistral --limit_mm_per_prompt 'image=4' --max_num_batched_tokens 65536 --gpu-memory-utilization 0.95 --max-model-len 65536
    
    pip install -U "huggingface_hub[cli]"
    
    huggingface-cli login
    
    
    
```
    curl http://64.247.196.11:8000/v1/chat/completions \
      -H "Content-Type: application/json" \
      -d '{
        "model": "mistralai/Pixtral-12B-2409",
        "messages": [{"role": "user", "content": "Hello, how are you?"}]
      }'
```
    
    
    
    
```
    curl --location 'http://64.247.196.11:8000/v1/chat/completions' \
    --header 'Content-Type: application/json' \
    --header 'Authorization: Bearer token' \
    --data '{
        "model": "mistralai/Pixtral-12B-2409",
        "messages": [
          {
            "role": "user",
            "content": [
                {"type" : "text", "text": "Describe this image in detail please in Chinese."},
                {"type": "image_url", "image_url": {"url": "https://s3.amazonaws.com/cms.ipressroom.com/338/files/201808/5b894ee1a138352221103195_A680%7Ejogging-edit/A680%7Ejogging-edit_hero.jpg"}},
                {"type" : "text", "text": "and this one as well. Answer in Chinese."},
                {"type": "image_url", "image_url": {"url": "https://www.wolframcloud.com/obj/resourcesystem/images/a0e/a0ee3983-46c6-4c92-b85d-059044639928/6af8cfb971db031b.png"}}
            ]
          }
        ]
      }'
```
    
    
    
    from openai import OpenAI
    
```
    # æ­£ç¡®åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
    client = OpenAI(
        base_url="http://64.247.196.11:8000/v1",
        api_key="test"
    )
```
    
```
    response = client.chat.completions.create(
      model="mistralai/Pixtral-12B-2409",
      messages=[
        {
          "role": "user",
          "content": [
            {"type": "text", "text": "What's in this image?"},
            {
              "type": "image_url",
              "image_url": {
                "url": "https://s3.amazonaws.com/cms.ipressroom.com/338/files/201808/5b894ee1a138352221103195_A680%7Ejogging-edit/A680%7Ejogging-edit_hero.jpg",
              },
            },
          ],
        }
      ],
      max_tokens=1024,
    )
```
    
    print(response.choices[0])
    
    
    
    
    import base64
    from openai import OpenAI
    
```
    def encode_image(image_path):
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
```
    
```
    # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
    client = OpenAI(
        base_url="http://64.247.196.11:8000/v1",
        api_key="test"
    )
```
    
    # æœ¬åœ°å›¾ç‰‡è·¯å¾„
    image_path = "./dog.jpg"
    
    # ç¼–ç å›¾ç‰‡
    base64_image = encode_image(image_path)
    
```
    response = client.chat.completions.create(
      model="mistralai/Pixtral-12B-2409",
      messages=[
        {
          "role": "user",
          "content": [
            {"type": "text", "text": "What's in this image?"},
            {
              "type": "image_url",
              "image_url": {
                "url": f"data:image/jpeg;base64,{base64_image}",
              },
            },
          ],
        }
      ],
      max_tokens=1024,
    )
```
    
    print(response.choices[0])
    
    
    
    
    

###  stream 
    
    
    from openai import OpenAI
    import sys
    
```
    # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
    client = OpenAI(
        base_url="http://64.247.196.11:8000/v1",
        api_key="test"
    )
```
    
```
    # åˆ›å»ºæµå¼ completion è¯·æ±‚
    stream = client.chat.completions.create(
        model="mistralai/Pixtral-12B-2409",
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": "What's in this image?"},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": "https://s3.amazonaws.com/cms.ipressroom.com/338/files/201808/5b894ee1a138352221103195_A680%7Ejogging-edit/A680%7Ejogging-edit_hero.jpg",
                        },
                    },
                ],
            }
        ],
        max_tokens=1024,
        stream=True  # å¯ç”¨æµå¼è¾“å‡º
    )
```
    
```
    # å¤„ç†æµå¼å“åº”
    for chunk in stream:
        if chunk.choices[0].delta.content is not None:
            print(chunk.choices[0].delta.content, end='', flush=True)
```
    
    print()  # æœ€åæ‰“å°ä¸€ä¸ªæ¢è¡Œ
    
    
```
    import base64
    import sys
    from openai import OpenAI
```
    
    
```
    def encode_image(image_path):
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
```
    
    
```
    # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
    client = OpenAI(
        base_url="http://64.247.196.11:8000/v1",
        api_key="test"
    )
```
    
    # æœ¬åœ°å›¾ç‰‡è·¯å¾„
    image_path = "./dog.jpg"
    
    # ç¼–ç å›¾ç‰‡
    base64_image = encode_image(image_path)
    
```
    # åˆ›å»ºæµå¼ completion è¯·æ±‚
    stream = client.chat.completions.create(
        model="mistralai/Pixtral-12B-2409",
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": "What's in this image?"},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{base64_image}",
                        },
                    },
                ],
            }
        ],
        max_tokens=1024,
        stream=True  # å¯ç”¨æµå¼è¾“å‡º
    )
```
    
```
    # å¤„ç†æµå¼å“åº”
    for chunk in stream:
        if chunk.choices[0].delta.content is not None:
            print(chunk.choices[0].delta.content, end='', flush=True)
```
    
    print()  # æœ€åæ‰“å°ä¸€ä¸ªæ¢è¡Œ

###  UI Chatbot 
    
    
    #pip install streamlit
    #streamlit run bot.py
    
    
```
    import streamlit as st
    import base64
    from openai import OpenAI
    from io import BytesIO
```
    
    
    def encode_image(image_file):
        return base64.b64encode(image_file.getvalue()).decode('utf-8')
    
    
```
    def get_chat_response(client, messages):
        stream = client.chat.completions.create(
            model="mistralai/Pixtral-12B-2409",
            messages=messages,
            max_tokens=1024,
            stream=True
        )
        return stream
```
    
    
    st.title("å¤šæ¨¡æ€Chatbot")
    
```
    # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
    client = OpenAI(
        base_url="http://64.247.196.11:8000/v1",
        api_key="test"
    )
```
    
```
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if "messages" not in st.session_state:
        st.session_state.messages = []
```
    
```
    # æ˜¾ç¤ºèŠå¤©å†å²
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
```
    
    # å›¾ç‰‡ä¸Šä¼ 
    uploaded_file = st.file_uploader("ä¸Šä¼ å›¾ç‰‡", type=["jpg", "jpeg", "png"])
    
    # ç”¨æˆ·è¾“å…¥
    user_input = st.chat_input("è¾“å…¥ä½ çš„é—®é¢˜")
    
```
    if uploaded_file and user_input:
        # ç¼–ç å›¾ç‰‡
        base64_image = encode_image(uploaded_file)
```
    
```
        # åˆ›å»ºæ–°çš„ç”¨æˆ·æ¶ˆæ¯
        new_message = {
            "role": "user",
            "content": [
                {"type": "text", "text": user_input},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{base64_image}",
                    },
                },
            ]
        }
```
    
        st.session_state.messages.append({"role": "user", "content": user_input})
    
```
        with st.chat_message("user"):
            st.markdown(user_input)
            st.image(uploaded_file, caption="ä¸Šä¼ çš„å›¾ç‰‡", use_column_width=True)
```
    
```
        # è·å–AIå“åº”
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            for chunk in get_chat_response(client, [new_message]):
                if chunk.choices[0].delta.content is not None:
                    full_response += chunk.choices[0].delta.content
                    message_placeholder.markdown(full_response + "â–Œ")
            message_placeholder.markdown(full_response)
```
    
        st.session_state.messages.append({"role": "assistant", "content": full_response})
    
```
    st.sidebar.title("ä½¿ç”¨è¯´æ˜")
    st.sidebar.markdown("""
    1. ä¸Šä¼ ä¸€å¼ å›¾ç‰‡
    2. åœ¨è¾“å…¥æ¡†ä¸­è¾“å…¥ä½ çš„é—®é¢˜
    3. ç­‰å¾…AIåˆ†æå›¾ç‰‡å¹¶å›ç­”ä½ çš„é—®é¢˜
    """)
```

###  chainlit 
    
    
```
    import base64
    import chainlit as cl
    from openai import OpenAI
```
    
```
    # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
    client = OpenAI(
        base_url="http://64.247.196.48:8000/v1",
        api_key="test"
    )
```
    
```
    def encode_image(image_path):
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
```
    
```
    @cl.on_chat_start
    async def start():
        await cl.Message("æ¬¢è¿ä½¿ç”¨å›¾åƒåˆ†æåº”ç”¨!è¯·é€‰æ‹©ä¸€å¼ å›¾ç‰‡å¹¶è¾“å…¥æ‚¨çš„é—®é¢˜ï¼Œç„¶åç‚¹å‡»å‘é€ã€‚").send()
```
    
```
    @cl.on_message
    async def main(message: cl.Message):
        if not message.elements:
            await cl.Message("è¯·ä¸Šä¼ ä¸€å¼ å›¾ç‰‡å¹¶è¾“å…¥æ‚¨çš„é—®é¢˜ã€‚").send()
            return
```
    
```
        image = message.elements[0]
        if not image.mime.startswith("image"):
            await cl.Message("è¯·ä¸Šä¼ ä¸€ä¸ªæœ‰æ•ˆçš„å›¾ç‰‡æ–‡ä»¶ã€‚").send()
            return
```
    
```
        question = message.content
        if not question:
            await cl.Message("è¯·è¾“å…¥å…³äºå›¾ç‰‡çš„é—®é¢˜ã€‚").send()
            return
```
    
        await process_image(image.path, question)
    
    async def process_image(image_path, question):
        base64_image = encode_image(image_path)
    
```
        stream = client.chat.completions.create(
            model="mistralai/Pixtral-12B-2409",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": question},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}",
                            },
                        },
                    ],
                }
            ],
            max_tokens=1024,
            stream=True
        )
```
    
        msg = cl.Message(content="")
        await msg.send()
    
```
        full_response = ""
        for chunk in stream:
            if chunk.choices[0].delta.content is not None:
                content = chunk.choices[0].delta.content
                full_response += content
                await msg.stream_token(content)
```
    
        await msg.update()
    
    if __name__ == "__main__":
        cl.run()
