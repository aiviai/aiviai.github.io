---
layout: single  
title: "ðŸš€æŒ‘æˆ˜Gemini 2.5ï¼æœ€å¼ºå¼€æºä¼ä¸šçº§OCRå¤§æ¨¡åž‹InternVL3ï¼æœ¬åœ°éƒ¨ç½²æ•™ç¨‹+å®žæˆ˜æµ‹è¯„å…¨çºªå½•ï¼Œè½»æ¾æžå®šæ½¦è‰æ‰‹å†™æ±‰å­—ã€æ¨¡ç³ŠPDFæ‰«æä»¶ã€æ¨¡ç³Šå¤æ‚è¡¨æ ¼ï¼Œæ•ˆæžœç‚¸è£‚è¶…è¿‡äººçœ¼ï¼æ”¯æŒOpen WebUI"  
sidebar:
  nav: "docs"
date: 2025-04-20 10:00:00 +0800  
categories: LLMs
tags: [InternVL3, OCR, InternVL, multimodal, AI, VLM]
classes: wide  

author_profile: true  
---

è¿‘æ—¥ï¼Œä¸€ä¸ªé‡é‡çº§çš„å¼€æºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹ï¼ˆMLLMï¼‰æ–°æ˜Ÿæ¨ªç©ºå‡ºä¸–ã€‚ç”±ä¸Šæµ·äººå·¥æ™ºèƒ½å®žéªŒå®¤ã€å•†æ±¤ç§‘æŠ€ç ”ç©¶é™¢ç­‰å¤šå®¶æœºæž„è”åˆå¼€å‘çš„InternVL3æ¨¡åž‹ï¼Œä»¥å…¶å“è¶Šçš„æ€§èƒ½å’Œåˆ›æ–°çš„æž¶æž„è®¾è®¡ï¼Œæ­£åœ¨é‡æ–°å®šä¹‰å¼€æºå¤šæ¨¡æ€æ¨¡åž‹çš„å‘å±•è¾¹ç•Œã€‚

InternVL3æ¨¡åž‹é‡‡ç”¨äº†ä¸€ç§ç§°ä¸º"åŽŸç”Ÿå¤šæ¨¡æ€é¢„è®­ç»ƒ"çš„åˆ›æ–°æ–¹æ³•ï¼Œä¸Žä¼ ç»Ÿæ¨¡åž‹ä¸åŒï¼Œå®ƒæ²¡æœ‰å…ˆè®­ç»ƒçº¯æ–‡æœ¬å¤§è¯­è¨€æ¨¡åž‹å†é€‚é…è§†è§‰è¾“å…¥ï¼Œè€Œæ˜¯åœ¨å•ä¸€é¢„è®­ç»ƒé˜¶æ®µåŒæ—¶ä»Žå¤šæ ·åŒ–çš„å¤šæ¨¡æ€æ•°æ®å’Œçº¯æ–‡æœ¬è¯­æ–™ä¸­å…±åŒå­¦ä¹ è¯­è¨€èƒ½åŠ›å’Œå¤šæ¨¡æ€èƒ½åŠ›ã€‚è¿™ç§ç»Ÿä¸€çš„è®­ç»ƒèŒƒå¼æœ‰æ•ˆè§£å†³äº†ä¼ ç»ŸMLLMè®­ç»ƒæµç¨‹ä¸­å¸¸è§çš„å¤æ‚æ€§å’Œå¯¹é½æŒ‘æˆ˜ã€‚

### ðŸš€æœ¬ç¯‡ç¬”è®°æ‰€å¯¹åº”çš„è§†é¢‘ï¼š

- [ðŸ‘‰ðŸ‘‰ðŸ‘‰ é€šè¿‡å“”å“©å“”å“©è§‚çœ‹](https://www.bilibili.com/video/BV1QDLFzGEyL/)
- [ðŸ‘‰ðŸ‘‰ðŸ‘‰ é€šè¿‡YouTubeè§‚çœ‹](https://youtu.be/_EqUR0dYGtE)
- [ðŸ‘‰ðŸ‘‰ðŸ‘‰ æˆ‘çš„å¼€æºé¡¹ç›®](https://github.com/win4r/AISuperDomain)
- [ðŸ‘‰ðŸ‘‰ðŸ‘‰ è¯·æˆ‘å–å’–å•¡](https://ko-fi.com/aila)
- ðŸ‘‰ðŸ‘‰ðŸ‘‰ æˆ‘çš„å¾®ä¿¡ï¼šstoeng
- ðŸ‘‰ðŸ‘‰ðŸ‘‰ æ‰¿æŽ¥å¤§æ¨¡åž‹å¾®è°ƒã€RAGã€AIæ™ºèƒ½ä½“ã€AIç›¸å…³åº”ç”¨å¼€å‘ç­‰é¡¹ç›®ã€‚

### ðŸ”¥AIæ™ºèƒ½ä½“ç›¸å…³è§†é¢‘

1. [AIæ™ºèƒ½ä½“è§†é¢‘ 1](https://youtu.be/vYm0brFoMwA) 
2. [AIæ™ºèƒ½ä½“è§†é¢‘ 2](https://youtu.be/szTXELuaJos)  
3. [AIæ™ºèƒ½ä½“è§†é¢‘ 3](https://youtu.be/szTXELuaJos)  
4. [AIæ™ºèƒ½ä½“è§†é¢‘ 4](https://youtu.be/RxR3x_Uyq4c)  
5. [AIæ™ºèƒ½ä½“è§†é¢‘ 5](https://youtu.be/IrTEDPnEVvU)  


## æŠ€æœ¯åˆ›æ–°ç‚¹

InternVL3æ¨¡åž‹çš„æ ¸å¿ƒæŠ€æœ¯åˆ›æ–°åŒ…æ‹¬ï¼š

1. **å¯å˜è§†è§‰ä½ç½®ç¼–ç ï¼ˆV2PEï¼‰**ï¼šè¯¥æ¨¡åž‹å¼•å…¥äº†å¯å˜è§†è§‰ä½ç½®ç¼–ç æŠ€æœ¯ï¼Œä¸ºè§†è§‰ä»¤ç‰Œä½¿ç”¨æ›´å°ã€æ›´çµæ´»çš„ä½ç½®å¢žé‡ï¼Œä»Žè€Œæ”¯æŒæ›´é•¿çš„å¤šæ¨¡æ€ä¸Šä¸‹æ–‡ï¼Œè€Œæ— éœ€è¿‡åº¦æ‰©å±•ä½ç½®çª—å£ã€‚
2. **æ··åˆåå¥½ä¼˜åŒ–ï¼ˆMPOï¼‰**ï¼šä¸ºè§£å†³æ¨¡åž‹åœ¨æŽ¨ç†è¿‡ç¨‹ä¸­å¯èƒ½å‡ºçŽ°çš„åˆ†å¸ƒåç§»é—®é¢˜ï¼Œç ”ç©¶å›¢é˜Ÿé‡‡ç”¨äº†æ··åˆåå¥½ä¼˜åŒ–æŠ€æœ¯ï¼Œå¼•å…¥æ¥è‡ªæ­£è´Ÿæ ·æœ¬çš„é¢å¤–ç›‘ç£ï¼Œä»¥ä½¿æ¨¡åž‹å“åº”åˆ†å¸ƒä¸ŽçœŸå®žåˆ†å¸ƒä¿æŒä¸€è‡´ï¼Œä»Žè€Œæé«˜æŽ¨ç†æ€§èƒ½ã€‚
3. **æµ‹è¯•æ—¶æ‰©å±•ç­–ç•¥**ï¼šInternVL3é‡‡ç”¨äº†Best-of-Nè¯„ä¼°ç­–ç•¥å¹¶ä½¿ç”¨VisualPRM-8Bä½œä¸ºè¯„åˆ¤æ¨¡åž‹ï¼Œä¸ºæŽ¨ç†å’Œæ•°å­¦è¯„ä¼°é€‰æ‹©æœ€ä½³å“åº”ï¼Œæ˜¾è‘—æå‡äº†æ¨¡åž‹çš„æ•´ä½“æ€§èƒ½ã€‚

## æ€§èƒ½çªç ´

æ ¹æ®ç ”ç©¶å›¢é˜Ÿçš„å¹¿æ³›ç»éªŒè¯„ä¼°ï¼ŒInternVL3åœ¨å¤šç§å¤šæ¨¡æ€ä»»åŠ¡ä¸Šè¡¨çŽ°å‡ºè‰²ã€‚ç‰¹åˆ«å€¼å¾—ä¸€æçš„æ˜¯ï¼ŒInternVL3-78Båœ¨MMMUåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†72.2åˆ†çš„æˆç»©ï¼Œåˆ›ä¸‹äº†å¼€æºMLLMçš„æ–°çºªå½•ï¼Œå…¶èƒ½åŠ›ä¸Žé¢†å…ˆçš„ä¸“æœ‰æ¨¡åž‹ï¼ˆåŒ…æ‹¬ChatGPT-4oã€Claude 3.5 Sonnetå’ŒGemini 2.5 Proï¼‰ç›¸å½“ï¼ŒåŒæ—¶ä¿æŒäº†å¼ºå¤§çš„çº¯è¯­è¨€èƒ½åŠ›ã€‚

è¿™ä¸€æˆç»©æ ‡å¿—ç€å¼€æºå¤šæ¨¡æ€æ¨¡åž‹é¦–æ¬¡åœ¨è¿™ä¸€é‡è¦åŸºå‡†ä¸Šçªç ´70%çš„é—¨æ§›ï¼Œç›¸æ¯”äºŽä¹‹å‰çš„InternVL 2.5æ¨¡åž‹æœ‰äº†æ˜¾è‘—æå‡ã€‚

## å¹¿æ³›çš„åº”ç”¨åœºæ™¯

ä¸Žå‰ä»£InternVL 2.5ç›¸æ¯”ï¼ŒInternVL3ä¸ä»…åœ¨å¤šæ¨¡æ€æ„ŸçŸ¥å’ŒæŽ¨ç†èƒ½åŠ›æ–¹é¢è¡¨çŽ°æ›´ä½³ï¼Œè¿˜å°†å…¶å¤šæ¨¡æ€èƒ½åŠ›è¿›ä¸€æ­¥æ‰©å±•åˆ°å·¥å…·ä½¿ç”¨ã€GUIä»£ç†ã€å·¥ä¸šå›¾åƒåˆ†æžã€3Dè§†è§‰æ„ŸçŸ¥ç­‰é¢†åŸŸã€‚

è¿™ä½¿å¾—InternVL3åœ¨å®žé™…åº”ç”¨ä¸­å…·æœ‰æ›´å¹¿æ³›çš„ä»·å€¼ï¼Œä»ŽåŸºç¡€å›¾åƒç†è§£åˆ°å¤æ‚çš„è·¨æ¨¡æ€æŽ¨ç†ä»»åŠ¡ï¼Œéƒ½èƒ½è¡¨çŽ°å‡ºè‰²ã€‚

## å¼€æºè´¡çŒ®

éµå¾ªå¼€æ”¾ç§‘å­¦åŽŸåˆ™ï¼Œç ”ç©¶å›¢é˜Ÿå°†å…¬å¼€å‘å¸ƒInternVL3çš„è®­ç»ƒæ•°æ®å’Œæ¨¡åž‹æƒé‡ï¼Œä»¥ä¿ƒè¿›ä¸‹ä¸€ä»£MLLMçš„è¿›ä¸€æ­¥ç ”ç©¶å’Œå¼€å‘ã€‚è¿™ä¸€ä¸¾æŽªå¯¹å¼€æºAIç¤¾åŒºå…·æœ‰é‡è¦æ„ä¹‰ï¼Œä¸ºç ”ç©¶äººå‘˜å’Œå¼€å‘è€…æä¾›äº†å®è´µçš„èµ„æºã€‚

## æœªæ¥å±•æœ›

éšç€å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹çš„ä¸æ–­å‘å±•ï¼ŒInternVL3çš„åˆ›æ–°æŠ€æœ¯å’Œä¼˜å¼‚æ€§èƒ½ä¸ºæœªæ¥AIç³»ç»Ÿçš„å‘å±•æä¾›äº†æ–°çš„æ€è·¯å’Œå‚è€ƒã€‚æˆ‘ä»¬æœŸå¾…çœ‹åˆ°æ›´å¤šç ”ç©¶å›¢é˜ŸåŸºäºŽè¿™ä¸€å¼€æºæ¨¡åž‹è¿›è¡Œåˆ›æ–°ï¼ŒæŽ¨åŠ¨å¤šæ¨¡æ€AIæŠ€æœ¯åœ¨å„è¡Œå„ä¸šçš„è½åœ°åº”ç”¨ã€‚

---

### LMDeployæ–‡æ¡£

[https://github.com/InternLM/lmdeploy](https://github.com/InternLM/lmdeploy)

### Windowsç³»ç»Ÿå¼€å¯wslï¼š
[https://learn.microsoft.com/zh-cn/windows/wsl/install](https://learn.microsoft.com/zh-cn/windows/wsl/install)

### ðŸ”¥Open WebUIå®‰è£…

```python
pip install open-webui

open-webui serve

è®¿é—®ï¼šhttp://localhost:8080/
```

### ðŸ”¥æœ¬åœ°éƒ¨ç½²è¯¦ç»†å‘½ä»¤

```markdown
# AIè¶…å…ƒåŸŸé¢‘é“åŽŸåˆ›è§†é¢‘
# å®‰è£…Minicondaï¼ˆå¦‚æžœå°šæœªå®‰è£…ï¼‰
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda.sh
bash ~/miniconda.sh -b -p $HOME/miniconda
eval "$($HOME/miniconda/bin/conda shell.bash hook)"
echo 'export PATH="$HOME/miniconda/bin:$PATH"' >> ~/.bashrc
source ~/.bashrc
# AIè¶…å…ƒåŸŸé¢‘é“åŽŸåˆ›è§†é¢‘
conda create -n lmdeploy python=3.11 -y && conda activate lmdeploy

pip install lmdeploy partial_json_parser timm

# serve
lmdeploy serve api_server OpenGVLab/InternVL3-14B-Instruct --backend turbomind --server-port 23333 --tp 2 --chat-template internvl2_5

# è°ƒç”¨api
from openai import OpenAI

client = OpenAI(api_key='YOUR_API_KEY', base_url='http://0.0.0.0:23333/v1')
model_name = client.models.list().data[0].id
response = client.chat.completions.create(
    model=model_name,
    messages=[{
        'role':
        'user',
        'content': [{
            'type': 'text',
            'text': 'describe this image',
        }, {
            'type': 'image_url',
            'image_url': {
                'url':
                'https://modelscope.oss-cn-beijing.aliyuncs.com/resource/tiger.jpeg',
            },
        }],
    }],
    temperature=0.8,
    top_p=0.8)
print(response)
```

### Linux/Ubuntuå†…å­˜ã€æ˜¾å­˜ç›‘æŽ§è„šæœ¬

```python

#pip install psutil flask flask-cors gputil
#nohup python server.py > server_log.txt 2>&1 &

#!/usr/bin/env python3
"""
Server Metrics API - Provides real-time GPU, CPU and RAM usage via HTTP
"""

import json
import os
import time
import psutil
import subprocess
from flask import Flask, jsonify, Response
from flask_cors import CORS
import GPUtil

app = Flask(__name__)
CORS(app)  # Enable cross-origin requests

def get_ram_info():
    """Get RAM usage information"""
    memory = psutil.virtual_memory()
    return {
        "total": memory.total / (1024 ** 3),  # Convert to GB
        "used": memory.used / (1024 ** 3),
        "free": memory.available / (1024 ** 3),
        "percent": memory.percent
    }

def get_cpu_info():
    """Get CPU usage information"""
    # Get per-core CPU percentage over 0.5 second interval
    per_cpu_percent = psutil.cpu_percent(interval=0.5, percpu=True)
    
    # Get overall CPU percentage
    overall_percent = sum(per_cpu_percent) / len(per_cpu_percent)
    
    # Get CPU frequency information if available
    freq = psutil.cpu_freq()
    frequency = None
    if freq:
        frequency = {
            "current": freq.current,
            "min": freq.min if hasattr(freq, 'min') else None,
            "max": freq.max if hasattr(freq, 'max') else None
        }
    
    return {
        "overall_percent": overall_percent,
        "per_cpu_percent": per_cpu_percent,
        "frequency": frequency,
        "core_count": psutil.cpu_count(logical=True),
        "physical_core_count": psutil.cpu_count(logical=False)
    }

def get_gpu_info():
    """Get GPU usage information"""
    try:
        gpus = GPUtil.getGPUs()
        gpu_data = []
        
        for i, gpu in enumerate(gpus):
            gpu_data.append({
                "id": i,
                "name": gpu.name,
                "load": gpu.load * 100,  # Convert to percentage
                "memory": {
                    "total": gpu.memoryTotal,  # In GB
                    "used": gpu.memoryUsed,    # In GB
                    "free": gpu.memoryFree,    # In GB
                    "percent": (gpu.memoryUsed / gpu.memoryTotal) * 100
                },
                "temperature": gpu.temperature
            })
        
        return gpu_data
    except Exception as e:
        print(f"Error retrieving GPU info: {e}")
        return []

@app.route('/metrics', methods=['GET'])
def metrics():
    """API endpoint to get all metrics"""
    data = {
        "timestamp": time.time(),
        "cpu": get_cpu_info(),
        "ram": get_ram_info(),
        "gpu": get_gpu_info()
    }
    return jsonify(data)

@app.route('/metrics/stream', methods=['GET'])
def metrics_stream():
    """Stream metrics as server-sent events"""
    def generate():
        while True:
            data = {
                "timestamp": time.time(),
                "cpu": get_cpu_info(),
                "ram": get_ram_info(),
                "gpu": get_gpu_info()
            }
            yield f"data: {json.dumps(data)}\n\n"
            time.sleep(1)  # Update every second

    return Response(generate(), mimetype='text/event-stream')

if __name__ == '__main__':
    # Install dependencies if not already installed
    try:
        import GPUtil
        import flask
        import flask_cors
    except ImportError:
        print("Installing required packages...")
        os.system('pip install psutil flask flask-cors gputil')
        print("Please restart the script after installation.")
        exit(1)
        
    # Run the server on all interfaces on port 5000
    app.run(host='0.0.0.0', port=5000, threaded=True)
```