---
layout: single  
title: "ğŸš€æœ¬åœ°éƒ¨ç½²è°·æ­ŒPaliGemma 2 mixè§†è§‰å¤§æ¨¡å‹ï¼è½»æ¾è¯†åˆ«å›¾åƒï¼æ”¯æŒæ ‡è®°ç‰©ä½“ä½ç½®ï¼æ”¯æŒORCæå–æ–‡å­—å†…å®¹ï¼æ”¯æŒè‡ªç„¶è¯­è¨€é—®ç­”ã€æ–‡æ¡£ç†è§£ã€è§†è§‰é—®ç­”ï¼5åˆ†é’Ÿå¸¦ä½ æŒæ¡æœ¬åœ°éƒ¨ç½²å…¨æµç¨‹ï¼é™„å…¨éƒ¨ä»£ç ä¸æ³¨é‡Šè¯´æ˜"  
sidebar:
  nav: "docs"
date: 2025-02-20 10:00:00 +0800  
categories: LLMs
tags: [PaliGemma, PaliGemma 2, PaliGemma 2 mix, å¤šæ¨¡æ€å¤§æ¨¡å‹, OCR]
classes: wide  

author_profile: true  
---

PaliGemma 2 mixæ˜¯Googleæœ€æ–°å‘å¸ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹(VLM),æ˜¯PaliGemma 2ç³»åˆ—çš„ä¸€ä¸ªé‡è¦ç»„æˆéƒ¨åˆ†ã€‚è¿™ä¸ªæ¨¡å‹åœ¨å¤šç§è§†è§‰è¯­è¨€ä»»åŠ¡ä¸Šè¿›è¡Œäº†å¾®è°ƒ,å¯ä»¥ç›´æ¥ç”¨äºå¤šç§åº”ç”¨åœºæ™¯ã€‚

PaliGemma 2 mixä»£è¡¨äº†è§†è§‰è¯­è¨€æ¨¡å‹çš„æœ€æ–°è¿›å±•,ä¸ºå¤šæ¨¡æ€AIåº”ç”¨å¼€è¾Ÿäº†æ–°çš„å¯èƒ½æ€§ã€‚å®ƒçš„å¤šåŠŸèƒ½æ€§å’Œå³æ’å³ç”¨ç‰¹æ€§ä½¿å…¶æˆä¸ºç ”ç©¶å’Œå®é™…åº”ç”¨çš„ç†æƒ³é€‰æ‹©ã€‚


### **æœ¬ç¯‡ç¬”è®°æ‰€å¯¹åº”çš„è§†é¢‘ï¼š**

- [ğŸ‘‰ğŸ‘‰ğŸ‘‰ é€šè¿‡å“”å“©å“”å“©è§‚çœ‹](https://www.bilibili.com/video/BV1sNAWeBELq/)
- [ğŸ‘‰ğŸ‘‰ğŸ‘‰ é€šè¿‡YouTubeè§‚çœ‹](https://youtu.be/a_bfJCM1xrg)
- [ğŸ‘‰ğŸ‘‰ğŸ‘‰ æˆ‘çš„å¼€æºé¡¹ç›®](https://github.com/win4r/AISuperDomain)
- [ğŸ‘‰ğŸ‘‰ğŸ‘‰ è¯·æˆ‘å–å’–å•¡](https://ko-fi.com/aila)
- ğŸ‘‰ğŸ‘‰ğŸ‘‰ æˆ‘çš„å¾®ä¿¡ï¼šstoeng ã€åŠ æˆ‘è¯·æ³¨æ˜æ¥æ„ã€‘
- ğŸ‘‰ğŸ‘‰ğŸ‘‰ æ‰¿æ¥å¤§æ¨¡å‹å¾®è°ƒã€RAGã€AIæ™ºèƒ½ä½“ã€AIç›¸å…³åº”ç”¨å¼€å‘ç­‰é¡¹ç›®ã€‚


### ğŸš€ç®€ä»‹


## æ¨¡å‹æ¶æ„ä¸ç‰¹ç‚¹

PaliGemma 2 mixåŸºäºä¸¤ä¸ªå…³é”®æŠ€æœ¯:

1. SigLIPè§†è§‰ç¼–ç å™¨:å¤„ç†å›¾åƒå’Œè§†é¢‘ç­‰è§†è§‰æ•°æ®
2. Gemma 2è¯­è¨€æ¨¡å‹:å¤„ç†å¤šè¯­è¨€æ–‡æœ¬ç†è§£å’Œç”Ÿæˆ

è¿™ä¸¤ä¸ªç»„ä»¶å…±åŒæ„æˆäº†ä¸€ä¸ªå¼ºå¤§çš„è§†è§‰è¯­è¨€æ¨¡å‹,èƒ½å¤Ÿæ— ç¼åœ°è§£é‡Šå’Œè¿æ¥è§†è§‰ä¸æ–‡æœ¬ä¿¡æ¯ã€‚

ä¸»è¦ç‰¹ç‚¹åŒ…æ‹¬:

- **å¤šç§è§„æ¨¡**: æä¾›3Bã€10Bå’Œ28Bå‚æ•°çš„ç‰ˆæœ¬,é€‚åº”ä¸åŒçš„è®¡ç®—èµ„æºéœ€æ±‚
- **å¤šåˆ†è¾¨ç‡æ”¯æŒ**: æ”¯æŒ224x224ã€448x448å’Œ896x896ç­‰å¤šç§å›¾åƒè¾“å…¥åˆ†è¾¨ç‡,é€‚ç”¨äºä¸åŒçš„ä»»åŠ¡éœ€æ±‚
- **å¤šè¯­è¨€èƒ½åŠ›**: ç»§æ‰¿è‡ªGemma 2,å…·æœ‰å¼ºå¤§çš„å¤šè¯­è¨€å¤„ç†èƒ½åŠ›
- **å³æ’å³ç”¨**: ç»è¿‡å¤šä»»åŠ¡å¾®è°ƒ,å¯ä»¥ç›´æ¥ä½¿ç”¨,æ— éœ€é¢å¤–è®­ç»ƒ

## æ”¯æŒçš„ä»»åŠ¡

PaliGemma 2 mixèƒ½å¤Ÿæ‰§è¡Œå¤šç§è§†è§‰è¯­è¨€ä»»åŠ¡,åŒ…æ‹¬ä½†ä¸é™äº:

- å›¾åƒå’ŒçŸ­è§†é¢‘å­—å¹•ç”Ÿæˆ
- è§†è§‰é—®ç­”
- å…‰å­¦å­—ç¬¦è¯†åˆ«(OCR)
- å¯¹è±¡æ£€æµ‹å’Œåˆ†å‰²
- æ–‡æ¡£ç†è§£(å¦‚å›¾è¡¨å’Œå›¾è§£åˆ†æ)
- ç§‘å­¦é—®é¢˜å›ç­”

## ä½¿ç”¨æ–¹æ³•

PaliGemma 2 mixæ”¯æŒå¼€æ”¾å¼æç¤ºå’Œç‰¹å®šä»»åŠ¡å‰ç¼€ä¸¤ç§ä½¿ç”¨æ–¹å¼:

1. **å¼€æ”¾å¼æç¤º**: ç›´æ¥ä½¿ç”¨è‡ªç„¶è¯­è¨€æè¿°ä»»åŠ¡,æ¨¡å‹ä¼šè‡ªåŠ¨ç†è§£å¹¶æ‰§è¡Œç›¸åº”æ“ä½œ
2. **ä»»åŠ¡å‰ç¼€**: ä½¿ç”¨ç‰¹å®šæ ¼å¼çš„å‰ç¼€æ¥æŒ‡å®šä»»åŠ¡ç±»å‹,å¦‚"caption {lang}"ç”¨äºç”Ÿæˆå›¾åƒæè¿°

å¯¹äºå¯¹è±¡æ£€æµ‹å’Œå›¾åƒåˆ†å‰²ä»»åŠ¡,ä»éœ€ä½¿ç”¨ç‰¹å®šçš„ä»»åŠ¡å‰ç¼€:

- "detect {object description}": ç”¨äºå¯¹è±¡æ£€æµ‹
- "segment {object description}; {object description}": ç”¨äºå›¾åƒåˆ†å‰²

## æ€§èƒ½å¯¹æ¯”

åœ¨å„ç§ä»»åŠ¡ä¸Š,PaliGemma 2 mixå±•ç°å‡ºä¼˜ç§€çš„æ€§èƒ½:

- **å›¾åƒæè¿°**: 10B/448ç‰ˆæœ¬èƒ½ç”Ÿæˆæ›´è¯¦ç»†ã€å‡†ç¡®çš„å›¾åƒæè¿°,ç›¸æ¯”3B/448ç‰ˆæœ¬
- **è§†è§‰é—®ç­”**: åœ¨ç®€å•é—®é¢˜ä¸Š,3Bå’Œ10Bç‰ˆæœ¬éƒ½èƒ½ç»™å‡ºå‡†ç¡®ç­”æ¡ˆ
- **OCR**: èƒ½å‡†ç¡®è¯†åˆ«å›¾åƒä¸­çš„æ–‡å­—,å¹¶ç”¨äºåç»­çš„é—®ç­”ä»»åŠ¡

## åº”ç”¨å‰æ™¯

PaliGemma 2 mixä¸ºç ”ç©¶äººå‘˜å’Œå¼€å‘è€…æä¾›äº†å¼ºå¤§çš„å·¥å…·,å¯åº”ç”¨äº:

- æ™ºèƒ½å›¾åƒåˆ†æå’Œæè¿°
- è‡ªåŠ¨æ–‡æ¡£å¤„ç†å’Œç†è§£
- é«˜çº§è§†è§‰æœç´¢ç³»ç»Ÿ
- è¾…åŠ©åŒ»ç–—è¯Šæ–­(å¦‚æ”¾å°„å½±åƒåˆ†æ)
- ç§‘å­¦ç ”ç©¶è¾…åŠ©å·¥å…·

### ğŸ”¥Demo:

[https://huggingface.co/spaces/google/paligemma2-10b-mix](https://huggingface.co/spaces/google/paligemma2-10b-mix)

### ğŸš€å¾®è°ƒPaliGemmaè§†é¢‘

âœ…å›½å†…é€šè¿‡å“”å“©å“”å“©è§‚çœ‹ [https://b23.tv/iCJzMTr](https://b23.tv/iCJzMTr)

âœ…æµ·å¤–é€šè¿‡YouTubeè§‚çœ‹ [https://youtu.be/8WrfOGgGkck](https://youtu.be/8WrfOGgGkck)

### ğŸš€æœ¬åœ°éƒ¨ç½²

```python
# ä¸‹è½½Minicondaå®‰è£…è„šæœ¬
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh

# æ·»åŠ æ‰§è¡Œæƒé™
chmod +x Miniconda3-latest-Linux-x86_64.sh

# è¿è¡Œå®‰è£…è„šæœ¬
./Miniconda3-latest-Linux-x86_64.sh

# æ¿€æ´»condaå‘½ä»¤
source ~/.bashrc

#anaconda
https://www.anaconda.com/download/success

# åˆ›å»ºä¸€ä¸ªPython 3.9çš„ç¯å¢ƒ
conda create -n paligemma python=3.11 -y

# æ¿€æ´»ç¯å¢ƒ
conda activate paligemma

# å¦‚æœæœ‰NVIDIA GPU,å®‰è£…CUDAç‰ˆæœ¬çš„PyTorch
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia -y

# å¦‚æœæ²¡æœ‰GPU,å®‰è£…CPUç‰ˆæœ¬çš„PyTorch
conda install pytorch torchvision torchaudio cpuonly -c pytorch -y

# å®‰è£…transformers
pip install transformers gradio pillow numpy sympy==1.13.1 accelerate>=0.26.0

pip install gradio pillow numpy

pip install sympy==1.13.1

pip install 'accelerate>=0.26.0'

python -c "import torch; import transformers; import gradio; print('æ‰€æœ‰ä¾èµ–å·²æ­£ç¡®å®‰è£…')"

huggingface-cli login

```

### Demo

```python
import gradio as gr
from transformers import (
    PaliGemmaProcessor,
    PaliGemmaForConditionalGeneration,
)
import torch
from PIL import Image
import numpy as np

# æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„GPU
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")

# åˆå§‹åŒ–æ¨¡å‹å’Œå¤„ç†å™¨
model_id = "google/paligemma2-10b-mix-448"  # ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹ç‰ˆæœ¬

try:
    # ä½¿ç”¨æ›´ä¿å®ˆçš„åŠ è½½è®¾ç½®
    model = PaliGemmaForConditionalGeneration.from_pretrained(
        model_id,
        torch_dtype=torch.float32,  # ä½¿ç”¨float32è€Œä¸æ˜¯bfloat16ä»¥æé«˜å…¼å®¹æ€§
        device_map="auto",
        low_cpu_mem_usage=True
    ).eval()
    
    processor = PaliGemmaProcessor.from_pretrained(model_id)
    print("Model and processor loaded successfully")
except Exception as e:
    print(f"Error loading model: {e}")
    raise

def process_image(image, task_type, question="", objects=""):
    """å¤„ç†å›¾ç‰‡å¹¶è¿”å›ç»“æœ"""
    try:
        # æ ¹æ®ä»»åŠ¡ç±»å‹æ„å»ºprompt
        if task_type == "æè¿°å›¾åƒ":
            prompt = "describe en"
        elif task_type == "OCRæ–‡å­—è¯†åˆ«":
            prompt = "ocr"
        elif task_type == "å›ç­”é—®é¢˜":
            prompt = f"answer en {question}"
        elif task_type == "æ£€æµ‹ç‰©ä½“":
            prompt = f"detect {objects}"
        else:
            return "è¯·é€‰æ‹©æœ‰æ•ˆçš„ä»»åŠ¡ç±»å‹"
        
        # ç¡®ä¿å›¾åƒæ˜¯PILæ ¼å¼
        if isinstance(image, np.ndarray):
            image = Image.fromarray(image)
        
        # å‡†å¤‡æ¨¡å‹è¾“å…¥
        model_inputs = processor(
            text=prompt,
            images=image,
            return_tensors="pt"
        )
        
        # å°†è¾“å…¥ç§»åˆ°æ­£ç¡®çš„è®¾å¤‡ä¸Š
        model_inputs = {k: v.to(device) for k, v in model_inputs.items()}
        
        input_len = model_inputs["input_ids"].shape[-1]
        
        # ç”Ÿæˆç»“æœ
        with torch.inference_mode():
            generation = model.generate(
                **model_inputs,
                max_new_tokens=100,
                do_sample=False
            )
            generation = generation[0][input_len:]
            result = processor.decode(generation, skip_special_tokens=True)
        
        return result
    except Exception as e:
        return f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}"

# åˆ›å»ºGradioç•Œé¢
with gr.Blocks() as demo:
    gr.Markdown("# PaliGemma 2 æ¼”ç¤º")
    gr.Markdown("ä¸Šä¼ å›¾ç‰‡å¹¶é€‰æ‹©ä»»åŠ¡ç±»å‹æ¥è·å–åˆ†æç»“æœ")
    
    with gr.Row():
        with gr.Column():
            # è¾“å…¥éƒ¨åˆ†
            image_input = gr.Image(label="ä¸Šä¼ å›¾ç‰‡")
            task_type = gr.Radio(
                choices=["æè¿°å›¾åƒ", "OCRæ–‡å­—è¯†åˆ«", "å›ç­”é—®é¢˜", "æ£€æµ‹ç‰©ä½“"],
                label="é€‰æ‹©ä»»åŠ¡ç±»å‹",
                value="æè¿°å›¾åƒ"
            )
            
            # æ¡ä»¶è¾“å…¥
            with gr.Group():
                question_input = gr.Textbox(
                    label="é—®é¢˜",
                    placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜",
                    visible=False
                )
                objects_input = gr.Textbox(
                    label="æ£€æµ‹ç‰©ä½“",
                    placeholder="è¯·è¾“å…¥è¦æ£€æµ‹çš„ç‰©ä½“ï¼Œç”¨åˆ†å·åˆ†éš”",
                    visible=False
                )
            
            submit_btn = gr.Button("å¼€å§‹åˆ†æ")
        
        with gr.Column():
            # è¾“å‡ºéƒ¨åˆ†
            output_text = gr.Textbox(label="åˆ†æç»“æœ")
    
    # åŠ¨æ€æ˜¾ç¤º/éšè—è¾“å…¥æ¡†
    def update_inputs(task):
        return {
            question_input: gr.update(visible=(task == "å›ç­”é—®é¢˜")),
            objects_input: gr.update(visible=(task == "æ£€æµ‹ç‰©ä½“"))
        }
    
    task_type.change(
        fn=update_inputs,
        inputs=[task_type],
        outputs=[question_input, objects_input]
    )
    
    # å¤„ç†æäº¤
    submit_btn.click(
        fn=process_image,
        inputs=[
            image_input,
            task_type,
            question_input,
            objects_input
        ],
        outputs=output_text
    )

if __name__ == "__main__":
    # æ·»åŠ å¼‚å¸¸å¤„ç†
    try:
        # å¯åŠ¨æ—¶ä¸è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨ï¼Œå¹¶å…è®¸å¤–éƒ¨è®¿é—®
        demo.launch(share=True, inbrowser=False, server_name="0.0.0.0")
    except Exception as e:
        print(f"å¯åŠ¨æœåŠ¡æ—¶å‡ºç°é”™è¯¯: {e}")
```