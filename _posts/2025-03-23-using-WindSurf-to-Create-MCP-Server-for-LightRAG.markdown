---
layout: single
title: "ğŸš€Cursoré™ä½æ™ºå•†ï¼WindSurfé›¶ä»£ç å¼€å‘MCP Serverï¼äº”åˆ†é’Ÿè½»æ¾å®ç°LightRAG+MCPä¸ºClaudeå’ŒAutoGenæŒ‚è½½çŸ¥è¯†åº“ï¼å¢å¼ºClaudeå’ŒAutoGençš„çŸ¥è¯†åº“æ£€ç´¢èƒ½åŠ›"
sidebar:
  nav: "docs"
date: 2025-03-23 00:00:00 +0800
categories: AIAgents
tags: [MCP, MCP Server, Cursor, WindSurf, AIç¼–ç¨‹]
classes: wide
author_profile: true
---


ä½¿ç”¨WindSurfå¼€å‘LightRAG MCPæœåŠ¡å™¨ï¼Œå¢å¼ºClaudeå’ŒAutoGençš„çŸ¥è¯†åº“èƒ½åŠ›

æœ¬è§†é¢‘å±•ç¤ºå¦‚ä½•ä½¿ç”¨WindSurfï¼ˆæ— éœ€ç¼–å†™ä»£ç ï¼‰å¼€å‘ä¸€ä¸ªLightRAG MCPæœåŠ¡å™¨ï¼Œå¹¶å°†å…¶é›†æˆåˆ°Claudeæ¡Œé¢ç‰ˆå’ŒAutoGenæ™ºèƒ½ä½“æ¡†æ¶ä¸­ï¼Œæä¾›å¼ºå¤§çš„çŸ¥è¯†åº“æ£€ç´¢åŠŸèƒ½ã€‚

### ğŸš€æœ¬ç¯‡ç¬”è®°æ‰€å¯¹åº”çš„è§†é¢‘ï¼š

- [ğŸ‘‰ğŸ‘‰ğŸ‘‰ é€šè¿‡å“”å“©å“”å“©è§‚çœ‹](https://www.bilibili.com/video/BV1P6XYYgEjY/)
- [ğŸ‘‰ğŸ‘‰ğŸ‘‰ é€šè¿‡YouTubeè§‚çœ‹](https://youtu.be/KGZ_zM6Xi-U)
- [ğŸ‘‰ğŸ‘‰ğŸ‘‰ æˆ‘çš„å¼€æºé¡¹ç›®](https://github.com/win4r/AISuperDomain)
- [ğŸ‘‰ğŸ‘‰ğŸ‘‰ è¯·æˆ‘å–å’–å•¡](https://ko-fi.com/aila)
- ğŸ‘‰ğŸ‘‰ğŸ‘‰ æˆ‘çš„å¾®ä¿¡ï¼šstoeng
- ğŸ‘‰ğŸ‘‰ğŸ‘‰ æ‰¿æ¥å¤§æ¨¡å‹å¾®è°ƒã€RAGã€AIæ™ºèƒ½ä½“ã€AIç›¸å…³åº”ç”¨å¼€å‘ç­‰é¡¹ç›®ã€‚

### ğŸ”¥AIæ™ºèƒ½ä½“ç›¸å…³è§†é¢‘

1. [AIæ™ºèƒ½ä½“è§†é¢‘ 1](https://youtu.be/vYm0brFoMwA)  
2. [AIæ™ºèƒ½ä½“è§†é¢‘ 2](https://youtu.be/szTXELuaJos)  
3. [AIæ™ºèƒ½ä½“è§†é¢‘ 3](https://youtu.be/szTXELuaJos)  
4. [AIæ™ºèƒ½ä½“è§†é¢‘ 4](https://youtu.be/RxR3x_Uyq4c)  
5. [AIæ™ºèƒ½ä½“è§†é¢‘ 5](https://youtu.be/IrTEDPnEVvU)  


## è§†é¢‘äº®ç‚¹ï¼š
- è¯¦ç»†æ¼”ç¤ºå¦‚ä½•å®‰è£…LightRAGå¹¶æ„å»ºè‡ªå®šä¹‰çŸ¥è¯†åº“
- é€šè¿‡WindSurfå¿«é€Ÿæ„å»ºMCPæœåŠ¡å™¨ï¼Œæ— éœ€æ‰‹åŠ¨ç¼–å†™ä»£ç 
- æ”¯æŒå¤šç§æ£€ç´¢æ–¹å¼ï¼šnaiveã€localã€globalå’Œhybrid
- å°†å¾®è°ƒLlama3çš„æŠ€æœ¯æ–‡æ¡£ä½œä¸ºç¤ºä¾‹çŸ¥è¯†åº“
- å®Œæ•´æ¼”ç¤ºä¸Claudeæ¡Œé¢ç‰ˆå’ŒAutoGenæ¡†æ¶çš„é›†æˆè¿‡ç¨‹

## æŠ€æœ¯ç‰¹ç‚¹ï¼š
- LightRAGåŸºäºå›¾ç»“æ„çš„æ£€ç´¢å¢å¼ºç”Ÿæˆç³»ç»Ÿ
- é€šè¿‡æ„å»ºçŸ¥è¯†å›¾è°±ä¼˜åŒ–æ–‡æœ¬ç´¢å¼•å’Œæ£€ç´¢
- èåˆå‘é‡ä¸ç»“æ„åŒ–å…³ç³»ï¼Œå¢å¼ºä¿¡æ¯è¿è´¯æ€§
- æ”¯æŒå¢é‡æ›´æ–°ï¼Œé™ä½è®¡ç®—æˆæœ¬
- åœ¨å¤æ‚ä¿¡æ¯æ£€ç´¢å’Œè·¨æ–‡æ¡£æ¨ç†æ–¹é¢è¡¨ç°ä¼˜å¼‚

æœ¬è§†é¢‘æ‰€ä½¿ç”¨çš„ä»£ç å’ŒæŒ‡ä»¤å¯åœ¨è§†é¢‘ä¸‹æ–¹æè¿°æ æˆ–è¯„è®ºåŒºæ‰¾åˆ°ï¼Œä¹Ÿå¯é€šè¿‡åšå®¢æŸ¥æ‰¾å¯¹åº”ç¬”è®°ã€‚

### WindSurf Prompt

```bash

source .venv/bin/activate
execute @task.md 
```

### Claude desktop app prompt

```bash
 Using lightrag-server naive_search Tool to Search for "æ•°æ®è´¨é‡æ§åˆ¶æµç¨‹"ï¼Œå¹¶ç”¨ä¸­æ–‡å›ç­”
```

### AutoGen

```bash

pip install -U "autogen-ext[mcp]"

pip install -U "autogen-agentchat"

import asyncio

from autogen_agentchat.agents import AssistantAgent
from autogen_ext.models.openai import OpenAIChatCompletionClient
from autogen_ext.tools.mcp import StdioServerParams, mcp_server_tools

async def main() -> None:
    # Get the fetch tool from mcp-server-fetch.
    rag_mcp_server = StdioServerParams(
        command="/Users/charlesqin/PycharmProjects/ligtrag-test/.venv/bin/python",
        args=["/Users/charlesqin/PycharmProjects/ligtrag-test/mcp_server.py"],
        env={"OPENAI_API_KEY": "sk-proj-xxxxxxxx"}
    )
    tools = await mcp_server_tools(rag_mcp_server)

    # Create an agent that can use the fetch tool.
    model_client = OpenAIChatCompletionClient(model="gpt-4o-mini")
    agent = AssistantAgent(name="fetcher", model_client=model_client, tools=tools, reflect_on_tool_use=True)  # type: ignore

    # Let the agent fetch the content of a URL and summarize it.
    result = await agent.run(task="Using lightrag-server naive_search Tool to Search for 'æ•°æ®è´¨é‡æ§åˆ¶æµç¨‹'ï¼Œå¹¶ç”¨ä¸­æ–‡å›ç­”")
    print(result.messages[-1].content)

asyncio.run(main())

```

### MCPé…ç½®æ–‡ä»¶

```bash
{
  "mcpServers": {
    "lightrag": {
      "command": "/Users/charlesqin/PycharmProjects/ligtrag-test/.venv/bin/python",
      "args": ["/Users/charlesqin/PycharmProjects/ligtrag-test/mcp_server.py"],
      "env": {
        "OPENAI_API_KEY": "sk-proj--"
      }
    }
  }
}
```

```bash
#--------------------------å®‰è£…LightRAG--------------------------#

git clone https://github.com/HKUDS/LightRAG.git
cd LightRAG
pip install -e .
cd ..
export OPENAI_API_KEY=sk-proj-xxxxxxx

curl https://raw.githubusercontent.com/win4r/mytest/refs/heads/main/book.txt > ./book.txt

#--------------------------OpenAI--------------------------#

import os
import asyncio
from lightrag import LightRAG, QueryParam
from lightrag.llm.openai import gpt_4o_mini_complete, openai_embed
from lightrag.kg.shared_storage import initialize_pipeline_status

WORKING_DIR = "./mybook"

if not os.path.exists(WORKING_DIR):
    os.mkdir(WORKING_DIR)

async def initialize_rag():
    rag = LightRAG(
        working_dir=WORKING_DIR,
        embedding_func=openai_embed,
        llm_model_func=gpt_4o_mini_complete,
        # llm_model_func=gpt_4o_complete
    )

    await rag.initialize_storages()
    await initialize_pipeline_status()

    return rag

def main():
    # Initialize RAG instance
    rag = asyncio.run(initialize_rag())

    with open("./book.txt", "r", encoding="utf-8") as f:
        rag.insert(f.read())

    # Perform naive search
    print(
        rag.query(
            "What is the Self-Consistency Prompt?", param=QueryParam(mode="naive")
        )
    )

    # Perform local search
    print(
        rag.query(
            "What is the Self-Consistency Prompt?", param=QueryParam(mode="local")
        )
    )

    # Perform global search
    print(
        rag.query(
            "What is the Self-Consistency Prompt?", param=QueryParam(mode="global")
        )
    )

    # Perform hybrid search
    print(
        rag.query(
            "What are the top themes in this story?", param=QueryParam(mode="hybrid")
        )
    )

if __name__ == "__main__":
    main()
    
    
 

```

### windsurf Prompt

```markdown
### task:

ä¸º LightRAG æ„å»ºä¸€ä¸ª MCP æœåŠ¡å™¨(MCP Server)ã€‚  

è¯¥æœåŠ¡å™¨åº”å…è®¸æˆ‘è¾“å…¥ä»»æ„æŸ¥è¯¢æ–‡æœ¬ï¼Œå¹¶ä½¿ç”¨å››ç§ä¸åŒçš„ MCP å·¥å…·æ‰§è¡Œæœç´¢æ“ä½œï¼š
**æœ´ç´ æœç´¢ã€æœ¬åœ°æœç´¢ã€å…¨å±€æœç´¢å’Œæ··åˆæœç´¢**ã€‚  

### æ”¯æŒå¤šç§æŸ¥è¯¢æ¨¡å¼ï¼š  

- **æœ´ç´ æœç´¢ï¼ˆNaive Searchï¼‰**ï¼šå¯¹æ’å…¥çš„å†…å®¹æ‰§è¡Œç›´æ¥æœç´¢ã€‚  
- **æœ¬åœ°æœç´¢ï¼ˆLocal Searchï¼‰**ï¼šåœ¨æ’å…¥æ–‡æ¡£çš„å±€éƒ¨ä¸Šä¸‹æ–‡ä¸­æ£€ç´¢ç»“æœã€‚  
- **å…¨å±€æœç´¢ï¼ˆGlobal Searchï¼‰**ï¼šå¯¹æ•´ä¸ªæ•°æ®é›†è¿›è¡Œå…¨é¢æœç´¢ã€‚  
- **æ··åˆæœç´¢ï¼ˆHybrid Searchï¼‰**ï¼šç»“åˆæœ¬åœ°æœç´¢å’Œå…¨å±€æœç´¢çš„ç‰¹ç‚¹ï¼Œä»¥æé«˜ç»“æœçš„ç›¸å…³æ€§å’Œä¸€è‡´æ€§ã€‚  

**å·¥ä½œç›®å½•ï¼ˆWORKING_DIRï¼‰**è·¯å¾„ä¸ºï¼š  
`/Users/charlesqin/PycharmProjects/ligtrag-test`  

è¯·æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼ˆvenvï¼‰ï¼š
cd /Users/charlesqin/Documents/test-mcp
source .venv/bin/activate

export OPENAI_API_KEY=sk-proj-xxxxxxx

Here's the Code and Response for the LightRAG:

### Code (app.py):

import os
import asyncio
from lightrag import LightRAG, QueryParam
from lightrag.llm.openai import gpt_4o_mini_complete, openai_embed
from lightrag.kg.shared_storage import initialize_pipeline_status

WORKING_DIR = "./mybook"

if not os.path.exists(WORKING_DIR):
    os.mkdir(WORKING_DIR)

async def initialize_rag():
    rag = LightRAG(
        working_dir=WORKING_DIR,
        embedding_func=openai_embed,
        llm_model_func=gpt_4o_mini_complete,
        # llm_model_func=gpt_4o_complete
    )

    await rag.initialize_storages()
    await initialize_pipeline_status()

    return rag

def main():
    # Initialize RAG instance
    rag = asyncio.run(initialize_rag())

    with open("./book.txt", "r", encoding="utf-8") as f:
        rag.insert(f.read())

    # Perform naive search
    print(
        rag.query(
            "What is the Self-Consistency Prompt?", param=QueryParam(mode="naive")
        )
    )

    # Perform local search
    print(
        rag.query(
            "What is the Self-Consistency Prompt?", param=QueryParam(mode="local")
        )
    )

    # Perform global search
    print(
        rag.query(
            "What is the Self-Consistency Prompt?", param=QueryParam(mode="global")
        )
    )

    # Perform hybrid search
    print(
        rag.query(
            "What are the top themes in this story?", param=QueryParam(mode="hybrid")
        )
    )

if __name__ == "__main__":
    main()
    
    

### Response:

[Full response logs showing the initialization and search results]

(.venv) charlesqin@charless-MacBook-Pro test-mcp % python app.py
INFO: Process 6536 Shared-Data created for Single Process
INFO:nano-vectordb:Load (124, 1536) data
INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': './mybook/vdb_entities.json'} 124 data
INFO:nano-vectordb:Load (110, 1536) data
INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': './mybook/vdb_relationships.json'} 110 data
INFO:nano-vectordb:Load (9, 1536) data
INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': './mybook/vdb_chunks.json'} 9 data
INFO: Process 6536 initialized updated flags for namespace: [full_docs]
INFO: Process 6536 ready to initialize storage namespace: [full_docs]
INFO: Process 6536 initialized updated flags for namespace: [text_chunks]
INFO: Process 6536 ready to initialize storage namespace: [text_chunks]
INFO: Process 6536 initialized updated flags for namespace: [entities]
INFO: Process 6536 initialized updated flags for namespace: [relationships]
INFO: Process 6536 initialized updated flags for namespace: [chunks]
INFO: Process 6536 initialized updated flags for namespace: [chunk_entity_relation]
INFO: Process 6536 initialized updated flags for namespace: [llm_response_cache]
INFO: Process 6536 ready to initialize storage namespace: [llm_response_cache]
INFO: Process 6536 initialized updated flags for namespace: [doc_status]
INFO: Process 6536 ready to initialize storage namespace: [doc_status]
INFO: Process 6536 storage namespace already initialized: [full_docs]
INFO: Process 6536 storage namespace already initialized: [text_chunks]
INFO: Process 6536 storage namespace already initialized: [llm_response_cache]
INFO: Process 6536 storage namespace already initialized: [doc_status]
INFO: Process 6536 Pipeline namespace initialized
## æ•°æ®è´¨é‡æ§åˆ¶æµç¨‹

æ•°æ®è´¨é‡æ§åˆ¶æµç¨‹åœ¨ç¡®ä¿ç”¨äºæ¨¡å‹å¾®è°ƒçš„è®­ç»ƒæ•°æ®ç¬¦åˆæ ‡å‡†æ–¹é¢è‡³å…³é‡è¦ã€‚ç‰¹åˆ«æ˜¯åœ¨åŒ»ç–—å’Œé‡‘èé¢†åŸŸï¼Œè¿™ä¸€è¿‡ç¨‹ç¡®ä¿æ•°æ®çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚ä»¥ä¸‹æ˜¯é’ˆå¯¹åŒ»ç–—é¢†åŸŸçš„æ•°æ®è´¨é‡æ§åˆ¶æµç¨‹ï¼š

### 1. æ•°æ®æ¥æºå®¡æ ¸

- **MedChat æ•°æ®é›†**ï¼šåŒ…å«åŒ»ç–—é—®ç­”å¯¹ï¼Œéœ€è¦ç¡®ä¿æ•°æ®çš„æ¥æºæ˜¯æƒå¨çš„å’Œå¯é çš„ã€‚
- **MeDAL æ•°æ®é›†**ï¼šä» PubMed æ‘˜è¦ä¸­æå–çš„ 1400 ä¸‡ç¯‡æ–‡ç« ï¼Œä»¥ä¿è¯åŒ»ç–—ä¿¡æ¯çš„çœŸå®æ€§å’Œæœ€æ–°æ€§ã€‚
- **åŒ»å­¦è¯Šæ–­æ•°æ®é›†**ï¼šç”¨äºç”Ÿæˆåˆæˆ Q&A æ•°æ®é›†ï¼Œç¡®ä¿æ•°æ®å¯ç”¨äºè®­ç»ƒå¹¶ç¬¦åˆåŒ»ç–—é¢†åŸŸçš„è¦æ±‚ã€‚

### 2. ä¸“ä¸šäººå‘˜å®¡æ ¸

- é€šè¿‡åŒ»å­¦ä¸“ä¸šäººå‘˜å¯¹æ”¶é›†åˆ°çš„æ•°æ®è¿›è¡Œå®¡æ ¸ï¼Œç¡®è®¤æ•°æ®çš„å‡†ç¡®æ€§å’Œé€‚ç”¨æ€§ã€‚
- å€ŸåŠ©ä¸“å®¶çŸ¥è¯†ç¡®ä¿æ•°æ®ä¸­çš„æœ¯è¯­å’Œå†…å®¹ç¬¦åˆåŒ»å­¦æ ‡å‡†å’Œç°å®æƒ…å†µã€‚

### 3. æœ¯è¯­æ ‡å‡†åŒ–

- å¯¹äºæ•°æ®é›†ä¸­ä½¿ç”¨çš„åŒ»å­¦æœ¯è¯­ï¼Œè¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ï¼Œä»¥ç¡®ä¿ä¸åŒæ•°æ®æºä¸­çš„æœ¯è¯­ä¸€è‡´ï¼Œé¿å…æ­§ä¹‰ã€‚

### 4. æƒå¨èµ„æ–™å¼•ç”¨

- å¼•ç”¨æƒå¨çš„åŒ»å­¦èµ„æ–™ï¼Œä»¥æ”¯æŒæ•°æ®çš„æœ‰æ•ˆæ€§å’Œå¯ä¿¡åº¦ã€‚è¿™èƒ½å¤Ÿæé«˜æ¨¡å‹åœ¨å¤„ç†åŒ»ç–—ç›¸å…³æŸ¥è¯¢æ—¶çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚

### 5. æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†

- å¯¹æ•°æ®è¿›è¡Œæ¸…æ´—ï¼Œå»é™¤å†—ä½™å’Œä¸ç›¸å…³çš„ä¿¡æ¯ï¼Œç¡®ä¿æ•°æ®çš„æ•´æ´ã€‚
- æ ¼å¼åŒ–æ•°æ®ï¼Œä½¿å…¶é€‚åˆæ¨¡å‹çš„è¾“å…¥è¦æ±‚ã€‚

è¿™äº›æ­¥éª¤å°†æœ‰æ•ˆä¿éšœæ•°æ®çš„é«˜è´¨é‡ï¼Œä¸ºåç»­çš„æ¨¡å‹è®­ç»ƒå¥ å®šåŸºç¡€ï¼Œå¹¶æå‡æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚

### References
- [KG] æ•°æ®è´¨é‡æ§åˆ¶ç­–ç•¥ (File: N/A)
- [DC] åŒ»ç–—é¢†åŸŸå¾®è°ƒæ¡ˆä¾‹åˆ†æ (File: N/A)
### æ•°æ®è´¨é‡æ§åˆ¶æµç¨‹

æ•°æ®è´¨é‡æ§åˆ¶æµç¨‹æ˜¯Metaä¸ºç¡®ä¿Llama 3è®­ç»ƒæ•°æ®é›†é«˜è´¨é‡è€Œå®æ–½çš„ä¸€ç³»åˆ—ç³»ç»Ÿæ€§æªæ–½ï¼Œæ—¨åœ¨æå‡æ•°æ®çš„æœ‰æ•ˆæ€§ä¸å¯é æ€§ã€‚è¯¥æµç¨‹åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªå…³é”®éƒ¨åˆ†ï¼š

1. **åŸºäºLLMçš„åˆ†ç±»å™¨**ï¼š
   - å¼€å‘å¤šç§åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„åˆ†ç±»å™¨ï¼Œç”¨äºç­›é€‰é«˜è´¨é‡çš„æç¤ºå’Œå“åº”ã€‚è¿™äº›åˆ†ç±»å™¨æœ‰åŠ©äºè‡ªåŠ¨åˆ¤æ–­æ•°æ®çš„ç›¸å…³æ€§å’Œå‡†ç¡®æ€§ã€‚

2. **ä¸»é¢˜åˆ†ç±»**ï¼š
   - åˆ©ç”¨å¾®è°ƒè¿‡çš„Llama 3 8Bæ¨¡å‹ä½œä¸ºä¸»é¢˜åˆ†ç±»å™¨ï¼Œå°†é‡‡é›†åˆ°çš„æ•°æ®åˆ†ç±»ä¸ºå¹¿æ³›ç±»åˆ«å’Œç‰¹å®šç±»åˆ«ï¼Œä»¥ä¾¿äºåç»­çš„æ•°æ®å¤„ç†å’Œåˆ†æã€‚

3. **é—®é¢˜æ£€æµ‹ä¸çº æ­£**ï¼š
   - å®æ–½åŸºäºè§„åˆ™çš„ç­–ç•¥ï¼Œè¯†åˆ«å¹¶è¿‡æ»¤ä¸è‰¯å†…å®¹ï¼Œä¾‹å¦‚è¿‡åº¦ä½¿ç”¨è¡¨æƒ…ç¬¦å·å’Œæ„Ÿå¹å·ã€ä»¥åŠé¢‘ç¹å‡ºç°çš„é“æ­‰è¯­æ°”ç­‰ã€‚æ­¤å¤–ï¼Œè¿˜ç¡®ä¿æ‰€æœ‰æ•°æ®éµå¾ªç»Ÿä¸€çš„æ ¼å¼è§„èŒƒã€‚

4. **æ•°æ®æ¸…æ´—**ï¼š
   - è¿›è¡Œé‡å¤å†…å®¹çš„å»é™¤ï¼Œä½è´¨é‡æ–‡æ¡£çš„è¿‡æ»¤ï¼Œä»¥åŠä¸ªäººèº«ä»½ä¿¡æ¯å’Œæˆäººå†…å®¹çš„ç§»é™¤ï¼Œä»¥ä¿è¯æ•°æ®é›†ä¸­åªæœ‰é«˜è´¨é‡ææ–™ã€‚

5. **æ•°æ®å¢å¼ºæŠ€æœ¯**ï¼š
   - é‡‡ç”¨å¤šç§æ•°æ®å¢å¼ºæŠ€æœ¯ï¼Œä¾‹å¦‚å˜ä½“ç”Ÿæˆå’Œéš¾åº¦é€’å¢ç­‰ï¼Œä»¥æå‡æ¨¡å‹è®­ç»ƒçš„å…¨é¢æ€§ä¸æœ‰æ•ˆæ€§ã€‚è¿™äº›å¢å¼ºæªæ–½æœ‰åŠ©äºæé«˜æ¨¡å‹å¯¹ä¸åŒåœºæ™¯çš„é€‚åº”èƒ½åŠ›ã€‚

é€šè¿‡ä¸Šè¿°æµç¨‹ï¼ŒMetaç¡®ä¿Llama 3æ‰€ä½¿ç”¨çš„æ•°æ®é›†å…·å¤‡é«˜è´¨é‡ï¼Œä»è€Œä¿ƒè¿›æ¨¡å‹æ€§èƒ½çš„ä¼˜åŒ–å’Œæå‡ã€‚

### å‚è€ƒæ–‡çŒ®

1. Metaå®æ–½çš„æ•°æ®è´¨é‡æ§åˆ¶æµç¨‹ [KG] Source content (File: unknown_source)
2. æ•°æ®æ¸…æ´—çš„å®šä¹‰ä¸Importance [KG] Source content (File: unknown_source)
3. æ•°æ®å¢å¼ºæŠ€æœ¯çš„åº”ç”¨ä¸ä¼˜åŠ¿ [KG] Source content (File: unknown_source)
### æ•°æ®è´¨é‡æ§åˆ¶æµç¨‹

æ•°æ®è´¨é‡æ§åˆ¶æµç¨‹æ˜¯ç”±Metaå®æ–½çš„ä¸€ç§ç³»ç»ŸåŒ–æ–¹æ³•ï¼Œæ—¨åœ¨ç¡®ä¿ç”¨äºè®­ç»ƒLlama 3çš„é«˜æ ‡å‡†æ•°æ®é›†ã€‚è¿™ä¸€æµç¨‹åŒ…æ‹¬å¤šä¸ªå…³é”®æ­¥éª¤ï¼Œä»¥æœ‰æ•ˆç»´æŠ¤æ•°æ®çš„é«˜è´¨é‡å’Œå¯é æ€§ï¼š

1. **æ•°æ®æ”¶é›†**ï¼šä¾æ®æ—¢å®šæ ‡å‡†å’Œç›®æ ‡ï¼Œæ”¶é›†å¤šæ ·åŒ–å’Œé«˜è´¨é‡çš„æ•°æ®ã€‚è¿™ä¸€æ­¥éª¤æ¶‰åŠæ˜ç¡®æ•°æ®æºå’Œæ”¶é›†æ–¹æ³•ï¼Œä»¥ç¡®ä¿æ•°æ®çš„ä»£è¡¨æ€§å’Œè¦†ç›–é¢ã€‚

2. **æ•°æ®æ¸…æ´—**ï¼šé€šè¿‡å»é™¤é‡å¤é¡¹ï¼Œè¿‡æ»¤ä½è´¨é‡æ–‡æ¡£ç­‰éªŒè¯æŠ€æœ¯ï¼Œç¡®ä¿æ•°æ®çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚è¿™æ˜¯æå‡è®­ç»ƒæ•°æ®è´¨é‡çš„å…³é”®ç¯èŠ‚ã€‚

3. **æ•°æ®éªŒè¯**ï¼šå¯¹æ”¶é›†çš„æ•°æ®è¿›è¡Œå®¡æŸ¥ï¼Œç¡®ä¿å…¶ç¬¦åˆé¢„è®¾çš„è¦æ±‚å’Œç‰¹ç‚¹ï¼Œé˜²æ­¢å› ä¸è‰¯æ•°æ®å½±å“æ¨¡å‹æ€§èƒ½ã€‚

4. **åˆè§„æ£€æŸ¥**ï¼šåœ¨æ•°æ®å¤„ç†è¿‡ç¨‹ä¸­ï¼Œå®¡æŸ¥æ½œåœ¨çš„æ³•å¾‹å’Œé“å¾·é—®é¢˜ï¼Œç¡®ä¿æ‰€ç”¨æ•°æ®çš„åˆç†æ€§å’Œåˆè§„æ€§ã€‚

5. **æŒç»­ç›‘æ§**ï¼šå®æ–½æŒç»­çš„è´¨é‡ç›‘æ§å’Œåé¦ˆæœºåˆ¶ï¼Œå®šæœŸè¯„ä¼°æ•°æ®é›†çš„è´¨é‡å’Œé€‚åº¦æ€§ï¼Œä»¥ä¾¿åŠæ—¶è¿›è¡Œè°ƒæ•´å’Œä¼˜åŒ–ã€‚

æ•°æ®è´¨é‡æ§åˆ¶æµç¨‹æ˜¯Llama 3å¾®è°ƒåŠåº”ç”¨ä¸­ä¸å¯æˆ–ç¼ºçš„ç»„æˆéƒ¨åˆ†ï¼Œå¸®åŠ©ç¡®ä¿AIæ¨¡å‹åœ¨è®­ç»ƒä¸­ä½¿ç”¨åˆ°çš„æ•°æ®èƒ½å¤Ÿæ”¯æŒå…¶æ€§èƒ½è¡¨ç°ã€‚

### References

- [KG] Metaå®æ–½çš„ä¸¥æ ¼æ•°æ®è´¨é‡æ§åˆ¶æµç¨‹ (File: unknown_source)
- [KG] Llama 3çš„é«˜æ ‡å‡†æ•°æ®é›† (File: unknown_source)
- [KG] æ•°æ®è´¨é‡æ§åˆ¶ç¡®ä¿æ¨¡å‹æ€§èƒ½çš„å½±å“ (File: unknown_source)
- [KG] ç®¡ç†å’Œé¢„å¤„ç†çš„æ•°æ®é›†çš„é‡è¦æ€§ (File: unknown_source)
### æ•°æ®è´¨é‡æ§åˆ¶æµç¨‹

Metaä¸ºLlama 3å®æ–½äº†ä¸¥æ ¼çš„æ•°æ®è´¨é‡æ§åˆ¶æµç¨‹ï¼Œä»¥ç¡®ä¿è®­ç»ƒæ‰€ç”¨æ•°æ®é›†çš„é«˜æ ‡å‡†ã€‚ä»¥ä¸‹æ˜¯è¯¥æµç¨‹çš„å…³é”®ç»„æˆéƒ¨åˆ†ï¼š

1. **åŸºäºLLMçš„åˆ†ç±»å™¨**ï¼š
   - å¼€å‘å¤šç§åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„åˆ†ç±»å™¨ï¼Œç”¨äºç­›é€‰é«˜è´¨é‡æç¤ºå’Œå“åº”ã€‚

2. **ä¸»é¢˜åˆ†ç±»**ï¼š
   - ä½¿ç”¨å¾®è°ƒè¿‡çš„Llama 3 8Bæ¨¡å‹ä½œä¸ºä¸»é¢˜åˆ†ç±»å™¨ï¼Œå°†æ•°æ®åˆ†ä¸ºå¹¿æ³›å’Œç‰¹å®šç±»åˆ«ï¼Œä»¥æé«˜åˆ†ç±»çš„å‡†ç¡®æ€§ã€‚

3. **é—®é¢˜æ£€æµ‹ä¸çº æ­£**ï¼š
   - **è¡¨æƒ…ç¬¦å·å’Œæ„Ÿå¹å·è¿‡åº¦ä½¿ç”¨**ï¼šå®æ–½åŸºäºè§„åˆ™çš„ç­–ç•¥ï¼Œè¯†åˆ«å¹¶è¿‡æ»¤æ­¤ç±»å…ƒç´ ã€‚
   - **è¿‡åº¦é“æ­‰è¯­æ°”**ï¼šè¯†åˆ«å¹¶è°ƒæ•´å¦‚â€œæˆ‘å¾ˆæŠ±æ­‰â€æˆ–â€œæˆ‘é“æ­‰â€ç­‰å¸¸è§çŸ­è¯­çš„é¢‘ç‡ã€‚
   - **æ ¼å¼ä¸€è‡´æ€§**ï¼šç¡®ä¿æ‰€æœ‰æ•°æ®éµå¾ªç»Ÿä¸€æ ¼å¼ï¼Œä»¥æå‡æ•°æ®é›†çš„æ•´ä½“è´¨é‡ã€‚

4. **æ•°æ®æ¸…æ´—**ï¼š
   - å»é™¤é‡å¤å†…å®¹ã€‚
   - è¿‡æ»¤ä½è´¨é‡æ–‡æ¡£ã€‚
   - ç§»é™¤ä¸ªäººèº«ä»½ä¿¡æ¯å’Œæˆäººå†…å®¹ï¼Œä»¥ä¿éšœæ•°æ®çš„åˆæ³•æ€§å’Œé“å¾·æ€§ã€‚

5. **æ•°æ®å¢å¼ºæŠ€æœ¯**ï¼š
   - é’ˆå¯¹å¾®è°ƒçš„ç›®æ ‡ï¼Œé‡‡ç”¨å„ç§æ•°æ®å¢å¼ºæŠ€æœ¯ä»¥æå‡æ•°æ®å¤šæ ·æ€§å’Œä½¿ç”¨æ•ˆæœã€‚è¿™åŒ…æ‹¬ç”Ÿæˆå˜ä½“ã€åˆ¶å®šéš¾åº¦é€’å¢çš„è®­ç»ƒæ ·æœ¬åŠå…¶å®ƒç‰¹å®šçš„æ–¹æ¡ˆã€‚

é€šè¿‡ä»¥ä¸Šæµç¨‹ï¼ŒMetaç¡®ä¿Llama 3æ¨¡å‹èƒ½å¤Ÿåœ¨é«˜è´¨é‡çš„æ•°æ®åŸºç¡€ä¸Šè¿›è¡Œè®­ç»ƒï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ€§èƒ½å’Œå¯é æ€§ã€‚

### References
- [KG] Data Quality Control Process (File: unknown_source)
- [KG] å®‰å…¨å¾®è°ƒçš„æŠ€æœ¯å®ç° (File: unknown_source)
- [KG] æ•°æ®æ¸…æ´— (File: unknown_source)
(.venv) charlesqin@charless-MacBook-Pro test-mcp % 

### The MCP document is:

# Example Clients
Source: https://modelcontextprotocol.io/clients

A list of applications that support MCP integrations

This page provides an overview of applications that support the Model Context Protocol (MCP). Each client may support different MCP features, allowing for varying levels of integration with MCP servers.

ğŸ”¥æ­¤å¤„çœç•¥ï¼Œå› ä¸ºæ–‡æ¡£è¿‡é•¿åšå®¢å±•ç¤ºä¸å‡ºæ¥äº†ï¼Œè¯·è‡ªè¡Œå‡†å¤‡MCPæ–‡æ¡£ã€‚MCPæ–‡æ¡£è¯·ä»è¿™é‡Œè·å–ï¼šhttps://modelcontextprotocol.io/llms-full.txt

Remember that Claude can help you modify and improve your server as requirements change over time.

Need more guidance? Just ask Claude specific questions about implementing MCP features or troubleshooting issues that arise.

```